{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 - Aprendizagem de máquina.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbih5qE7+jwsYWflLqVbp7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeusEstudos/RedesNeuraisFFNN/blob/main/Aprendizagem_de_m%C3%A1quina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REDE NEURAL COM PREDIÇÕES DE VOLUME ÚTIL DO RESERVATÓRIO DE FUNIL (RJ) BASEADO EM VARIÁVEIS CLIMÁTICAS"
      ],
      "metadata": {
        "id": "ZOZXezHSMF-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Importação das bibliotecas"
      ],
      "metadata": {
        "id": "js22vJ60MhHH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbl1C_827rfW",
        "outputId": "15cf5e5c-4885-410f-a972-236f14ff666b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Importação dos arquivos do seu Google Drive pelo Colab - https://colab.research.google.com/notebooks/io.ipynb \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Álgebra linear https://numpy.org/\n",
        "import numpy as np\n",
        "\n",
        "# Processamento/manipulação dos dados https://pandas.pydata.org/\n",
        "import pandas as pd\n",
        "\n",
        "# Gráficos https://matplotlib.org/\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Biblioteca Python para machine learning https://scikit-learn.org/stable/\n",
        "from sklearn.model_selection import train_test_split # Irá dividir o dataset em dois conjuntos: treino e teste\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler # escalonamento dos dados\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score # métricas\n",
        "\n",
        "# Código aberto para machine learning com API do keras, onde este é uma biblioteca de rede neural em Python https://www.tensorflow.org/guide/keras?hl=pt-br\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Nadam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Preparando o dataframe para iniciar a aprendizagem de máquina\n",
        "\n",
        "- df_estacao_reservatorio_renomeado"
      ],
      "metadata": {
        "id": "dv3mMCdbMpyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lendo o arquivo\n",
        "df_estacao_reservatorio = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/TCC_PUC-Minas/Dados/df_estacao_reservatorio.xlsx\") \n",
        "df_estacao_reservatorio.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym0G7m91Mxze",
        "outputId": "6af8a53d-5573-403a-855f-bb5341bb658c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5892 entries, 0 to 5891\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   data    5892 non-null   datetime64[ns]\n",
            " 1   evap    5892 non-null   float64       \n",
            " 2   inso    5892 non-null   float64       \n",
            " 3   prec    5892 non-null   float64       \n",
            " 4   temp    5892 non-null   float64       \n",
            " 5   umid    5892 non-null   float64       \n",
            " 6   vent    5892 non-null   int64         \n",
            " 7   volu    5892 non-null   float64       \n",
            "dtypes: datetime64[ns](1), float64(6), int64(1)\n",
            "memory usage: 368.4 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conversão da data para um formato que a machine learning compreenda com data unix\n",
        "df_estacao_reservatorio[\"DataUnix\"] = df_estacao_reservatorio[\"data\"].values.astype(np.int64) // 10 ** 9\n",
        "df_estacao_reservatorio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Q3CNhgstNn9H",
        "outputId": "93f46736-bb64-4a5b-d54e-55d2d794d69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           data  evap  inso  prec   temp   umid     vent   volu    DataUnix\n",
              "0    1993-01-04   0.0   0.2   1.2  23.32  80.75        0  77.40   726105600\n",
              "1    1993-02-04   1.5   0.1   0.0  21.92  93.75        0  78.06   728784000\n",
              "2    1993-03-04   0.8   1.5   5.7  23.16  78.00  1266667  78.22   731203200\n",
              "3    1993-04-04   1.3   8.2   0.0  23.96  76.75  1366667  78.22   733881600\n",
              "4    1993-05-04   1.5   7.8  28.6  23.84  77.75        0  78.39   736473600\n",
              "...         ...   ...   ...   ...    ...    ...      ...    ...         ...\n",
              "5887 2017-08-28   5.4  10.6   0.0  18.54  71.50   154332  26.73  1503878400\n",
              "5888 2017-09-30   4.3   0.0  23.8  19.12  97.25        0  14.81  1506729600\n",
              "5889 2017-11-14   8.9  12.2   0.0  22.06  55.00        0  26.38  1510617600\n",
              "5890 2017-11-17   9.5   9.0   0.0  24.16  68.75        0  24.77  1510876800\n",
              "5891 2017-04-12   2.7   3.2   2.4  23.72  83.75        0  30.68  1491955200\n",
              "\n",
              "[5892 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77ba5d40-c9f3-4100-ba5d-18b2055881e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>evap</th>\n",
              "      <th>inso</th>\n",
              "      <th>prec</th>\n",
              "      <th>temp</th>\n",
              "      <th>umid</th>\n",
              "      <th>vent</th>\n",
              "      <th>volu</th>\n",
              "      <th>DataUnix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1993-01-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>23.32</td>\n",
              "      <td>80.75</td>\n",
              "      <td>0</td>\n",
              "      <td>77.40</td>\n",
              "      <td>726105600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1993-02-04</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.92</td>\n",
              "      <td>93.75</td>\n",
              "      <td>0</td>\n",
              "      <td>78.06</td>\n",
              "      <td>728784000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1993-03-04</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>5.7</td>\n",
              "      <td>23.16</td>\n",
              "      <td>78.00</td>\n",
              "      <td>1266667</td>\n",
              "      <td>78.22</td>\n",
              "      <td>731203200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1993-04-04</td>\n",
              "      <td>1.3</td>\n",
              "      <td>8.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.96</td>\n",
              "      <td>76.75</td>\n",
              "      <td>1366667</td>\n",
              "      <td>78.22</td>\n",
              "      <td>733881600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1993-05-04</td>\n",
              "      <td>1.5</td>\n",
              "      <td>7.8</td>\n",
              "      <td>28.6</td>\n",
              "      <td>23.84</td>\n",
              "      <td>77.75</td>\n",
              "      <td>0</td>\n",
              "      <td>78.39</td>\n",
              "      <td>736473600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5887</th>\n",
              "      <td>2017-08-28</td>\n",
              "      <td>5.4</td>\n",
              "      <td>10.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.54</td>\n",
              "      <td>71.50</td>\n",
              "      <td>154332</td>\n",
              "      <td>26.73</td>\n",
              "      <td>1503878400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5888</th>\n",
              "      <td>2017-09-30</td>\n",
              "      <td>4.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.8</td>\n",
              "      <td>19.12</td>\n",
              "      <td>97.25</td>\n",
              "      <td>0</td>\n",
              "      <td>14.81</td>\n",
              "      <td>1506729600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5889</th>\n",
              "      <td>2017-11-14</td>\n",
              "      <td>8.9</td>\n",
              "      <td>12.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.06</td>\n",
              "      <td>55.00</td>\n",
              "      <td>0</td>\n",
              "      <td>26.38</td>\n",
              "      <td>1510617600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5890</th>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>9.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.16</td>\n",
              "      <td>68.75</td>\n",
              "      <td>0</td>\n",
              "      <td>24.77</td>\n",
              "      <td>1510876800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5891</th>\n",
              "      <td>2017-04-12</td>\n",
              "      <td>2.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.4</td>\n",
              "      <td>23.72</td>\n",
              "      <td>83.75</td>\n",
              "      <td>0</td>\n",
              "      <td>30.68</td>\n",
              "      <td>1491955200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5892 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77ba5d40-c9f3-4100-ba5d-18b2055881e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77ba5d40-c9f3-4100-ba5d-18b2055881e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77ba5d40-c9f3-4100-ba5d-18b2055881e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retirando a coluna data\n",
        "df_estacao_reservatorio_removido = df_estacao_reservatorio.drop(['data'], axis=1)\n",
        "df_estacao_reservatorio_removido"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NbTPanlmO9FG",
        "outputId": "7023447c-27ba-418d-da68-4a0d1340233a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      evap  inso  prec   temp   umid     vent   volu    DataUnix\n",
              "0      0.0   0.2   1.2  23.32  80.75        0  77.40   726105600\n",
              "1      1.5   0.1   0.0  21.92  93.75        0  78.06   728784000\n",
              "2      0.8   1.5   5.7  23.16  78.00  1266667  78.22   731203200\n",
              "3      1.3   8.2   0.0  23.96  76.75  1366667  78.22   733881600\n",
              "4      1.5   7.8  28.6  23.84  77.75        0  78.39   736473600\n",
              "...    ...   ...   ...    ...    ...      ...    ...         ...\n",
              "5887   5.4  10.6   0.0  18.54  71.50   154332  26.73  1503878400\n",
              "5888   4.3   0.0  23.8  19.12  97.25        0  14.81  1506729600\n",
              "5889   8.9  12.2   0.0  22.06  55.00        0  26.38  1510617600\n",
              "5890   9.5   9.0   0.0  24.16  68.75        0  24.77  1510876800\n",
              "5891   2.7   3.2   2.4  23.72  83.75        0  30.68  1491955200\n",
              "\n",
              "[5892 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91221ac0-9b42-4d16-bf23-6e096ad9c9a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>evap</th>\n",
              "      <th>inso</th>\n",
              "      <th>prec</th>\n",
              "      <th>temp</th>\n",
              "      <th>umid</th>\n",
              "      <th>vent</th>\n",
              "      <th>volu</th>\n",
              "      <th>DataUnix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>23.32</td>\n",
              "      <td>80.75</td>\n",
              "      <td>0</td>\n",
              "      <td>77.40</td>\n",
              "      <td>726105600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.92</td>\n",
              "      <td>93.75</td>\n",
              "      <td>0</td>\n",
              "      <td>78.06</td>\n",
              "      <td>728784000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>5.7</td>\n",
              "      <td>23.16</td>\n",
              "      <td>78.00</td>\n",
              "      <td>1266667</td>\n",
              "      <td>78.22</td>\n",
              "      <td>731203200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.3</td>\n",
              "      <td>8.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.96</td>\n",
              "      <td>76.75</td>\n",
              "      <td>1366667</td>\n",
              "      <td>78.22</td>\n",
              "      <td>733881600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.5</td>\n",
              "      <td>7.8</td>\n",
              "      <td>28.6</td>\n",
              "      <td>23.84</td>\n",
              "      <td>77.75</td>\n",
              "      <td>0</td>\n",
              "      <td>78.39</td>\n",
              "      <td>736473600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5887</th>\n",
              "      <td>5.4</td>\n",
              "      <td>10.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.54</td>\n",
              "      <td>71.50</td>\n",
              "      <td>154332</td>\n",
              "      <td>26.73</td>\n",
              "      <td>1503878400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5888</th>\n",
              "      <td>4.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.8</td>\n",
              "      <td>19.12</td>\n",
              "      <td>97.25</td>\n",
              "      <td>0</td>\n",
              "      <td>14.81</td>\n",
              "      <td>1506729600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5889</th>\n",
              "      <td>8.9</td>\n",
              "      <td>12.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.06</td>\n",
              "      <td>55.00</td>\n",
              "      <td>0</td>\n",
              "      <td>26.38</td>\n",
              "      <td>1510617600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5890</th>\n",
              "      <td>9.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.16</td>\n",
              "      <td>68.75</td>\n",
              "      <td>0</td>\n",
              "      <td>24.77</td>\n",
              "      <td>1510876800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5891</th>\n",
              "      <td>2.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.4</td>\n",
              "      <td>23.72</td>\n",
              "      <td>83.75</td>\n",
              "      <td>0</td>\n",
              "      <td>30.68</td>\n",
              "      <td>1491955200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5892 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91221ac0-9b42-4d16-bf23-6e096ad9c9a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91221ac0-9b42-4d16-bf23-6e096ad9c9a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91221ac0-9b42-4d16-bf23-6e096ad9c9a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# renomear coluna\n",
        "df_estacao_reservatorio_renomeado = df_estacao_reservatorio_removido.rename(columns={'DataUnix': 'data'})\n",
        "df_estacao_reservatorio_renomeado.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOoFxsj4PGl9",
        "outputId": "7d7cc2a9-b2a4-4756-f560-ce1f0fd338c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5892 entries, 0 to 5891\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   evap    5892 non-null   float64\n",
            " 1   inso    5892 non-null   float64\n",
            " 2   prec    5892 non-null   float64\n",
            " 3   temp    5892 non-null   float64\n",
            " 4   umid    5892 non-null   float64\n",
            " 5   vent    5892 non-null   int64  \n",
            " 6   volu    5892 non-null   float64\n",
            " 7   data    5892 non-null   int64  \n",
            "dtypes: float64(6), int64(2)\n",
            "memory usage: 368.4 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# listando as colunas do dataframe para coletá-los facilmente para o próximo passo\n",
        "list(df_estacao_reservatorio_renomeado.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulCRD9bJPbTe",
        "outputId": "2a9f7afc-656f-4490-c0d1-894873fd72a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['evap', 'inso', 'prec', 'temp', 'umid', 'vent', 'volu', 'data']"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VARIÁVEL X (em maiúsculo), o values transforma os valores em um array do numpy\n",
        "X = (df_estacao_reservatorio_renomeado[['evap', 'inso', 'prec', 'temp', 'umid', 'vent', 'data']]).values\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EACrDRPPiml",
        "outputId": "5a7f785a-d3e9-4c33-a790-4f680d1ce104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0000000e+00, 2.0000000e-01, 1.2000000e+00, ..., 8.0750000e+01,\n",
              "        0.0000000e+00, 7.2610560e+08],\n",
              "       [1.5000000e+00, 1.0000000e-01, 0.0000000e+00, ..., 9.3750000e+01,\n",
              "        0.0000000e+00, 7.2878400e+08],\n",
              "       [8.0000000e-01, 1.5000000e+00, 5.7000000e+00, ..., 7.8000000e+01,\n",
              "        1.2666670e+06, 7.3120320e+08],\n",
              "       ...,\n",
              "       [8.9000000e+00, 1.2200000e+01, 0.0000000e+00, ..., 5.5000000e+01,\n",
              "        0.0000000e+00, 1.5106176e+09],\n",
              "       [9.5000000e+00, 9.0000000e+00, 0.0000000e+00, ..., 6.8750000e+01,\n",
              "        0.0000000e+00, 1.5108768e+09],\n",
              "       [2.7000000e+00, 3.2000000e+00, 2.4000000e+00, ..., 8.3750000e+01,\n",
              "        0.0000000e+00, 1.4919552e+09]])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VARIÁVEL y (em minúsculo), o values transforma os valores em um array do numpy\n",
        "y = df_estacao_reservatorio_renomeado['volu'].values\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouDehO1APukl",
        "outputId": "2da66a12-38f6-4eee-e96c-5df74630a693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([77.4 , 78.06, 78.22, ..., 26.38, 24.77, 30.68])"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# definindo o tamanho da amostra separando-os nas 4 variáveis (X_treino, X_teste, y_treino, y_teste)\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "IMGt72wLP2E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exibindo a quantidade de cada variável após a divisão da amosta\n",
        "print(\"Quantidade de dados para o treino do X: \", len(X_treino))\n",
        "print(\"Quantidade de dados para o teste do X: \", len(X_teste))\n",
        "print(\"Quantidade de dados para o treino do y: \", len(y_treino))\n",
        "print(\"Quantidade de dados para o treino do y: \", len(y_teste))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxuLrRlPP5ft",
        "outputId": "9e605878-5a53-4bb0-c96b-c14abed3306e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de dados para o treino do X:  4419\n",
            "Quantidade de dados para o teste do X:  1473\n",
            "Quantidade de dados para o treino do y:  4419\n",
            "Quantidade de dados para o treino do y:  1473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# escalonamento dos dados, instanciando o StandardScaler deixando-o pronto para ser utilizado\n",
        "escalador = StandardScaler()"
      ],
      "metadata": {
        "id": "daVimyvCP-M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# padronizar o X_treino, normalizando com o fit_transform, com valores entre 0 e 1 para diminuir os ruídos e convergência na rede neural\n",
        "X_treino = escalador.fit_transform(X_treino)\n",
        "X_treino"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnbWDHreQAr1",
        "outputId": "89b5ffe8-02b2-4b38-86b3-d21a97302236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.61199678, -0.65179519, -0.39988599, ...,  0.90700409,\n",
              "        -0.82557428,  1.51293483],\n",
              "       [-0.91209034,  0.19588704, -0.39016268, ...,  0.44310983,\n",
              "         0.30058983, -1.52892398],\n",
              "       [-0.70187143, -1.47122134,  0.33908611, ...,  0.83741995,\n",
              "         0.0542408 ,  0.38724764],\n",
              "       ...,\n",
              "       [ 0.71710623,  0.84577675, -0.39988599, ..., -0.73982054,\n",
              "         1.14521264,  1.32963409],\n",
              "       [-1.06975452, -0.199698  ,  1.8170303 , ...,  0.07199442,\n",
              "         0.89886361,  1.40813093],\n",
              "       [-0.96464507, -1.49947741, -0.39988599, ...,  1.90437675,\n",
              "        -0.82557428, -1.29003899]])"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padronizar o X_teste, normalizando com o transform\n",
        "# as variáveis y_treino e y_teste não serão normalizadas, pois esses refletem a realidade do aprendizado da rede neural ao realizar seu teste\n",
        "X_teste = escalador.transform(X_teste)\n",
        "X_teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgxKWXYNQHX8",
        "outputId": "a3254e03-92ee-4f1e-f28b-a0bbe291a1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.71564606, -1.52773349,  0.66967889, ...,  0.97658823,\n",
              "        -0.82556055,  1.39964479],\n",
              "       [ 0.34922314, -0.68005126,  0.06683323, ...,  0.83741995,\n",
              "        -0.01614373,  1.19512868],\n",
              "       [-0.80698088, -1.0756363 , -0.39988599, ...,  0.65186224,\n",
              "        -0.01614373, -0.28527938],\n",
              "       ...,\n",
              "       [-0.85953561, -0.36923444, -0.39988599, ...,  0.46630454,\n",
              "        -0.82556161, -1.41139087],\n",
              "       [-1.06975452, -0.82133163, -0.21514297, ...,  0.99978294,\n",
              "        -0.82557428, -0.69303866],\n",
              "       [-0.70187143, -1.44296527, -0.35126941, ...,  1.11575651,\n",
              "        -0.26249275, -1.44363822]])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a rede neural passa por um processo de convergência, exibindo o momento do seu ponto ótimo\n",
        "parar_rede_neural = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=21)\n",
        "\n",
        "# o learning_rate é a velocidade com que a rede neural aprende, quanto menor o número mais lento é seu aprendizado\n",
        "velocidade_aprendizagem = Nadam(learning_rate=0.0003) "
      ],
      "metadata": {
        "id": "XoDW_9cBQKt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - iniciando a aprendizagem de máquina com a rede neural FeedForward\n",
        "\n",
        "A rede neural FeedForward irá prever o volume útil com base nas variáveis climáticas"
      ],
      "metadata": {
        "id": "ufB19giKQkZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instanciando o modelo senquencial, que é a rede neural FeedForward, onde iniciará a aprendizagem de máquina\n",
        "modelo = Sequential()\n",
        "\n",
        "# 1ª camada é a camada de entrada\n",
        "# que é a mesma QTD de variáveis do X_treino ('evap', 'inso', 'prec', 'temp', 'umid', 'vent', 'data') para a QTD de neurônios, sendo portanto 7 neurônios \n",
        "modelo.add(Dense(7, activation=\"relu\"))\n",
        "\n",
        "# camada oculta\n",
        "modelo.add(Dense(666, activation=\"relu\")) # 2ª camada com 666 neurônios\n",
        "\n",
        "# a última camada é a de saída\n",
        "# é a mesma QTD de variáveis do y_treino, o volume útil \n",
        "modelo.add(Dense(1)) \n",
        "\n",
        "# compila o modelo \n",
        "# obtém uma média entre o valor previsto e o real com o mse\n",
        "modelo.compile(optimizer=velocidade_aprendizagem, loss=\"mse\")"
      ],
      "metadata": {
        "id": "MmzIbgOvQniL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# o fit estará realizando o ajuste do modelo neural, usando a variável x do X_treino e y de y_treino\n",
        "# aqui ocorre o treino e o teste da rede neural\n",
        "modelo.fit(x=X_treino, y=y_treino, epochs=2500, validation_data=(X_teste, y_teste), callbacks=[parar_rede_neural])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIOEmJCBQ0CE",
        "outputId": "60ac42e6-ceee-4342-a83c-51360d12c634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2500\n",
            "139/139 [==============================] - 1s 3ms/step - loss: 2892.3606 - val_loss: 2390.4480\n",
            "Epoch 2/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 1834.6471 - val_loss: 1325.7145\n",
            "Epoch 3/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 1145.9307 - val_loss: 989.9532\n",
            "Epoch 4/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 926.5819 - val_loss: 851.9927\n",
            "Epoch 5/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 818.1442 - val_loss: 769.8351\n",
            "Epoch 6/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 751.9915 - val_loss: 717.0583\n",
            "Epoch 7/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 708.5491 - val_loss: 680.2858\n",
            "Epoch 8/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 676.9805 - val_loss: 651.8678\n",
            "Epoch 9/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 652.7467 - val_loss: 629.1462\n",
            "Epoch 10/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 634.1146 - val_loss: 612.1557\n",
            "Epoch 11/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 619.6687 - val_loss: 599.8972\n",
            "Epoch 12/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 608.2583 - val_loss: 589.7850\n",
            "Epoch 13/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 599.4188 - val_loss: 581.4781\n",
            "Epoch 14/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 592.5190 - val_loss: 574.8703\n",
            "Epoch 15/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 586.9630 - val_loss: 569.9148\n",
            "Epoch 16/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 582.3757 - val_loss: 567.5830\n",
            "Epoch 17/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 578.1755 - val_loss: 564.7381\n",
            "Epoch 18/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 574.9824 - val_loss: 560.7977\n",
            "Epoch 19/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 571.3871 - val_loss: 557.9014\n",
            "Epoch 20/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 569.1403 - val_loss: 556.9511\n",
            "Epoch 21/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 567.1460 - val_loss: 553.0992\n",
            "Epoch 22/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 564.9052 - val_loss: 551.8154\n",
            "Epoch 23/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 562.5965 - val_loss: 550.6419\n",
            "Epoch 24/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 560.9835 - val_loss: 549.4316\n",
            "Epoch 25/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 558.7002 - val_loss: 547.6163\n",
            "Epoch 26/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 557.0559 - val_loss: 550.3453\n",
            "Epoch 27/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 556.5062 - val_loss: 547.3358\n",
            "Epoch 28/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 554.2653 - val_loss: 546.4072\n",
            "Epoch 29/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 552.9752 - val_loss: 543.7436\n",
            "Epoch 30/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 551.5586 - val_loss: 545.3366\n",
            "Epoch 31/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 550.3428 - val_loss: 541.2488\n",
            "Epoch 32/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 549.2973 - val_loss: 540.5861\n",
            "Epoch 33/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 547.9002 - val_loss: 540.2775\n",
            "Epoch 34/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 546.8578 - val_loss: 538.6000\n",
            "Epoch 35/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 545.2517 - val_loss: 538.4017\n",
            "Epoch 36/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 545.2814 - val_loss: 537.1407\n",
            "Epoch 37/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 543.2776 - val_loss: 538.3496\n",
            "Epoch 38/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 542.7999 - val_loss: 536.0494\n",
            "Epoch 39/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 541.2266 - val_loss: 533.8730\n",
            "Epoch 40/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 540.5654 - val_loss: 533.1355\n",
            "Epoch 41/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 539.2974 - val_loss: 533.0814\n",
            "Epoch 42/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 538.0976 - val_loss: 532.5559\n",
            "Epoch 43/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 537.2799 - val_loss: 531.5629\n",
            "Epoch 44/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 536.2198 - val_loss: 530.5535\n",
            "Epoch 45/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 535.1552 - val_loss: 528.7148\n",
            "Epoch 46/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 534.3406 - val_loss: 528.5392\n",
            "Epoch 47/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 533.2685 - val_loss: 528.5083\n",
            "Epoch 48/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 532.4141 - val_loss: 527.0827\n",
            "Epoch 49/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 531.5952 - val_loss: 526.0190\n",
            "Epoch 50/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 530.8274 - val_loss: 526.1774\n",
            "Epoch 51/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 530.0035 - val_loss: 524.9638\n",
            "Epoch 52/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 529.0721 - val_loss: 524.6511\n",
            "Epoch 53/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 528.4611 - val_loss: 523.6430\n",
            "Epoch 54/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 527.3474 - val_loss: 522.8048\n",
            "Epoch 55/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 526.7743 - val_loss: 522.1390\n",
            "Epoch 56/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 525.5670 - val_loss: 521.6315\n",
            "Epoch 57/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 524.9421 - val_loss: 521.1008\n",
            "Epoch 58/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 524.1976 - val_loss: 520.2371\n",
            "Epoch 59/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 523.8140 - val_loss: 519.5095\n",
            "Epoch 60/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 522.8800 - val_loss: 519.4840\n",
            "Epoch 61/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 521.8971 - val_loss: 518.5798\n",
            "Epoch 62/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 521.3854 - val_loss: 518.4434\n",
            "Epoch 63/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 520.9335 - val_loss: 518.0085\n",
            "Epoch 64/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 519.6788 - val_loss: 516.8358\n",
            "Epoch 65/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 519.3058 - val_loss: 517.8503\n",
            "Epoch 66/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 518.6870 - val_loss: 515.4352\n",
            "Epoch 67/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 517.9016 - val_loss: 514.2057\n",
            "Epoch 68/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 517.3088 - val_loss: 514.8121\n",
            "Epoch 69/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 516.4161 - val_loss: 514.4476\n",
            "Epoch 70/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 515.6358 - val_loss: 512.3851\n",
            "Epoch 71/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 515.1890 - val_loss: 512.7584\n",
            "Epoch 72/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 514.3964 - val_loss: 511.5946\n",
            "Epoch 73/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 513.4567 - val_loss: 512.4149\n",
            "Epoch 74/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 513.3624 - val_loss: 510.2867\n",
            "Epoch 75/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 512.3812 - val_loss: 510.2427\n",
            "Epoch 76/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 511.9272 - val_loss: 509.3113\n",
            "Epoch 77/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 510.9536 - val_loss: 509.0000\n",
            "Epoch 78/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 510.3282 - val_loss: 508.1839\n",
            "Epoch 79/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 509.9724 - val_loss: 507.3947\n",
            "Epoch 80/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 509.4005 - val_loss: 507.2709\n",
            "Epoch 81/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 508.5233 - val_loss: 507.3786\n",
            "Epoch 82/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 508.1659 - val_loss: 506.3786\n",
            "Epoch 83/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 507.1700 - val_loss: 505.7969\n",
            "Epoch 84/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 506.4294 - val_loss: 506.5072\n",
            "Epoch 85/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 505.9716 - val_loss: 504.0584\n",
            "Epoch 86/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 505.3326 - val_loss: 504.0258\n",
            "Epoch 87/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 504.4169 - val_loss: 503.0747\n",
            "Epoch 88/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 503.4762 - val_loss: 502.8367\n",
            "Epoch 89/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 503.4526 - val_loss: 502.2427\n",
            "Epoch 90/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 502.6627 - val_loss: 501.6587\n",
            "Epoch 91/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 502.1335 - val_loss: 500.7279\n",
            "Epoch 92/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 501.6301 - val_loss: 500.1835\n",
            "Epoch 93/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 500.5198 - val_loss: 499.6661\n",
            "Epoch 94/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 499.7316 - val_loss: 500.8205\n",
            "Epoch 95/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 499.9007 - val_loss: 498.0219\n",
            "Epoch 96/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 499.3069 - val_loss: 497.9506\n",
            "Epoch 97/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 497.7678 - val_loss: 499.1490\n",
            "Epoch 98/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 497.8770 - val_loss: 496.7563\n",
            "Epoch 99/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 496.8938 - val_loss: 495.6144\n",
            "Epoch 100/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 496.4116 - val_loss: 495.8396\n",
            "Epoch 101/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 495.6801 - val_loss: 495.0135\n",
            "Epoch 102/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 495.2527 - val_loss: 495.0042\n",
            "Epoch 103/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 494.8887 - val_loss: 493.5314\n",
            "Epoch 104/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 494.0195 - val_loss: 494.2476\n",
            "Epoch 105/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 493.7860 - val_loss: 493.2908\n",
            "Epoch 106/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 493.0355 - val_loss: 491.9876\n",
            "Epoch 107/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 492.8164 - val_loss: 492.3860\n",
            "Epoch 108/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 491.8280 - val_loss: 491.9159\n",
            "Epoch 109/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 491.0893 - val_loss: 491.6720\n",
            "Epoch 110/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 491.0892 - val_loss: 489.6987\n",
            "Epoch 111/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 490.3816 - val_loss: 489.7325\n",
            "Epoch 112/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 489.5688 - val_loss: 488.7837\n",
            "Epoch 113/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 489.7479 - val_loss: 488.3853\n",
            "Epoch 114/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 488.5977 - val_loss: 488.3907\n",
            "Epoch 115/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 487.9842 - val_loss: 487.8625\n",
            "Epoch 116/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 487.5196 - val_loss: 486.9283\n",
            "Epoch 117/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 486.8578 - val_loss: 488.5275\n",
            "Epoch 118/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 486.5011 - val_loss: 486.4575\n",
            "Epoch 119/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 485.8358 - val_loss: 485.8134\n",
            "Epoch 120/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 485.0900 - val_loss: 485.8534\n",
            "Epoch 121/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 485.1136 - val_loss: 485.0813\n",
            "Epoch 122/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 485.0805 - val_loss: 484.4825\n",
            "Epoch 123/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 483.9662 - val_loss: 484.0405\n",
            "Epoch 124/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 484.0412 - val_loss: 482.9462\n",
            "Epoch 125/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 482.8391 - val_loss: 482.5743\n",
            "Epoch 126/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 482.8672 - val_loss: 482.2413\n",
            "Epoch 127/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 482.4117 - val_loss: 482.5846\n",
            "Epoch 128/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 482.1333 - val_loss: 482.1488\n",
            "Epoch 129/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 481.4494 - val_loss: 480.8423\n",
            "Epoch 130/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 481.5994 - val_loss: 480.8257\n",
            "Epoch 131/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 480.6981 - val_loss: 482.2085\n",
            "Epoch 132/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 480.5454 - val_loss: 482.1213\n",
            "Epoch 133/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 480.4802 - val_loss: 479.9657\n",
            "Epoch 134/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 479.7369 - val_loss: 479.7942\n",
            "Epoch 135/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 479.4897 - val_loss: 481.4529\n",
            "Epoch 136/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 479.2958 - val_loss: 478.5203\n",
            "Epoch 137/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 478.4526 - val_loss: 480.2036\n",
            "Epoch 138/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 478.5129 - val_loss: 477.9446\n",
            "Epoch 139/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 478.0716 - val_loss: 477.5163\n",
            "Epoch 140/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 477.4141 - val_loss: 477.7049\n",
            "Epoch 141/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 477.4966 - val_loss: 476.8936\n",
            "Epoch 142/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 476.9236 - val_loss: 476.8305\n",
            "Epoch 143/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 476.5952 - val_loss: 476.9257\n",
            "Epoch 144/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 476.1530 - val_loss: 477.5092\n",
            "Epoch 145/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 476.1604 - val_loss: 475.8413\n",
            "Epoch 146/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 475.7750 - val_loss: 475.8409\n",
            "Epoch 147/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 474.8438 - val_loss: 477.2336\n",
            "Epoch 148/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 475.1630 - val_loss: 475.6310\n",
            "Epoch 149/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 474.9102 - val_loss: 475.0896\n",
            "Epoch 150/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 474.3463 - val_loss: 475.0907\n",
            "Epoch 151/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 473.7038 - val_loss: 475.4547\n",
            "Epoch 152/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 473.8681 - val_loss: 474.1515\n",
            "Epoch 153/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 473.4587 - val_loss: 475.0263\n",
            "Epoch 154/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 472.5591 - val_loss: 475.3006\n",
            "Epoch 155/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 472.8818 - val_loss: 473.8864\n",
            "Epoch 156/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 473.2166 - val_loss: 472.9084\n",
            "Epoch 157/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 472.3294 - val_loss: 472.6251\n",
            "Epoch 158/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 471.7263 - val_loss: 473.3152\n",
            "Epoch 159/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 471.5204 - val_loss: 473.2253\n",
            "Epoch 160/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 471.2841 - val_loss: 473.2440\n",
            "Epoch 161/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 470.7994 - val_loss: 473.3387\n",
            "Epoch 162/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 470.7229 - val_loss: 470.9747\n",
            "Epoch 163/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 470.0412 - val_loss: 472.9444\n",
            "Epoch 164/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 470.4641 - val_loss: 472.0267\n",
            "Epoch 165/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 469.9681 - val_loss: 470.6784\n",
            "Epoch 166/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 469.0382 - val_loss: 470.7962\n",
            "Epoch 167/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 469.2851 - val_loss: 469.8847\n",
            "Epoch 168/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 469.2101 - val_loss: 470.2019\n",
            "Epoch 169/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 468.3075 - val_loss: 469.2927\n",
            "Epoch 170/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 468.1987 - val_loss: 468.3752\n",
            "Epoch 171/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 467.6805 - val_loss: 468.1363\n",
            "Epoch 172/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 467.6438 - val_loss: 467.6884\n",
            "Epoch 173/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 467.3358 - val_loss: 467.6696\n",
            "Epoch 174/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 467.0111 - val_loss: 468.7244\n",
            "Epoch 175/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 466.9297 - val_loss: 467.6832\n",
            "Epoch 176/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 466.2449 - val_loss: 466.8803\n",
            "Epoch 177/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 465.9824 - val_loss: 467.4812\n",
            "Epoch 178/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 466.2117 - val_loss: 466.4253\n",
            "Epoch 179/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 465.5246 - val_loss: 466.6194\n",
            "Epoch 180/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 464.5325 - val_loss: 468.9528\n",
            "Epoch 181/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 465.0989 - val_loss: 467.0369\n",
            "Epoch 182/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 465.1155 - val_loss: 467.3134\n",
            "Epoch 183/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 463.9594 - val_loss: 466.1872\n",
            "Epoch 184/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 464.1720 - val_loss: 464.8870\n",
            "Epoch 185/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 463.2962 - val_loss: 465.0637\n",
            "Epoch 186/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 463.2107 - val_loss: 464.2810\n",
            "Epoch 187/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 462.8218 - val_loss: 464.1153\n",
            "Epoch 188/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 462.4243 - val_loss: 464.8764\n",
            "Epoch 189/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 461.6974 - val_loss: 463.6728\n",
            "Epoch 190/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 462.4978 - val_loss: 464.2744\n",
            "Epoch 191/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 462.1467 - val_loss: 463.1800\n",
            "Epoch 192/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 460.5321 - val_loss: 462.7576\n",
            "Epoch 193/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 461.0876 - val_loss: 462.3673\n",
            "Epoch 194/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 460.6415 - val_loss: 462.5648\n",
            "Epoch 195/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 460.2131 - val_loss: 461.4651\n",
            "Epoch 196/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 460.1928 - val_loss: 461.5751\n",
            "Epoch 197/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 459.4622 - val_loss: 461.3876\n",
            "Epoch 198/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 459.8460 - val_loss: 460.9497\n",
            "Epoch 199/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 458.9008 - val_loss: 460.2989\n",
            "Epoch 200/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 458.9147 - val_loss: 460.5916\n",
            "Epoch 201/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 458.5005 - val_loss: 460.4193\n",
            "Epoch 202/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 458.1479 - val_loss: 461.1192\n",
            "Epoch 203/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 457.9912 - val_loss: 460.7834\n",
            "Epoch 204/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 457.8597 - val_loss: 460.2656\n",
            "Epoch 205/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 457.4548 - val_loss: 458.4213\n",
            "Epoch 206/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 457.4833 - val_loss: 459.0516\n",
            "Epoch 207/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 456.7329 - val_loss: 458.8949\n",
            "Epoch 208/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 456.4650 - val_loss: 458.1440\n",
            "Epoch 209/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 456.0622 - val_loss: 457.6768\n",
            "Epoch 210/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 456.0015 - val_loss: 458.1429\n",
            "Epoch 211/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 456.2643 - val_loss: 457.6078\n",
            "Epoch 212/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 455.4236 - val_loss: 457.7655\n",
            "Epoch 213/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 455.7981 - val_loss: 456.9084\n",
            "Epoch 214/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 454.6003 - val_loss: 457.1042\n",
            "Epoch 215/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 455.2952 - val_loss: 456.1624\n",
            "Epoch 216/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 453.8330 - val_loss: 455.5846\n",
            "Epoch 217/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 454.3603 - val_loss: 456.1716\n",
            "Epoch 218/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 454.0056 - val_loss: 456.1378\n",
            "Epoch 219/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 453.5251 - val_loss: 456.1670\n",
            "Epoch 220/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 453.0220 - val_loss: 456.1685\n",
            "Epoch 221/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 453.4483 - val_loss: 454.7108\n",
            "Epoch 222/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 452.4087 - val_loss: 454.8471\n",
            "Epoch 223/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 452.1819 - val_loss: 455.3267\n",
            "Epoch 224/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 452.3423 - val_loss: 453.4901\n",
            "Epoch 225/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 451.6246 - val_loss: 454.0613\n",
            "Epoch 226/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 451.1590 - val_loss: 453.6633\n",
            "Epoch 227/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 451.1837 - val_loss: 454.2509\n",
            "Epoch 228/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 451.3597 - val_loss: 452.3846\n",
            "Epoch 229/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 450.6362 - val_loss: 451.9038\n",
            "Epoch 230/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 449.7939 - val_loss: 452.6267\n",
            "Epoch 231/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 449.4226 - val_loss: 452.9428\n",
            "Epoch 232/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 449.2232 - val_loss: 451.8307\n",
            "Epoch 233/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 449.2769 - val_loss: 450.8159\n",
            "Epoch 234/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 448.9377 - val_loss: 452.6434\n",
            "Epoch 235/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 448.1360 - val_loss: 449.8005\n",
            "Epoch 236/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 447.9119 - val_loss: 453.3981\n",
            "Epoch 237/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 448.2974 - val_loss: 450.3777\n",
            "Epoch 238/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 447.5673 - val_loss: 450.4064\n",
            "Epoch 239/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 447.4183 - val_loss: 450.7083\n",
            "Epoch 240/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 447.1899 - val_loss: 449.6451\n",
            "Epoch 241/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 446.8080 - val_loss: 448.9123\n",
            "Epoch 242/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 445.6811 - val_loss: 449.7053\n",
            "Epoch 243/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 446.1874 - val_loss: 447.9979\n",
            "Epoch 244/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 446.1067 - val_loss: 448.6040\n",
            "Epoch 245/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 445.4003 - val_loss: 448.4966\n",
            "Epoch 246/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 444.5483 - val_loss: 449.7058\n",
            "Epoch 247/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 445.0669 - val_loss: 447.8260\n",
            "Epoch 248/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 444.6093 - val_loss: 446.8925\n",
            "Epoch 249/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 444.5631 - val_loss: 448.5571\n",
            "Epoch 250/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 444.6599 - val_loss: 447.4710\n",
            "Epoch 251/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 443.8326 - val_loss: 447.7585\n",
            "Epoch 252/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 442.7310 - val_loss: 450.1298\n",
            "Epoch 253/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 443.7861 - val_loss: 446.9214\n",
            "Epoch 254/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 443.3364 - val_loss: 445.8729\n",
            "Epoch 255/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 443.0865 - val_loss: 445.6508\n",
            "Epoch 256/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 442.4379 - val_loss: 445.4149\n",
            "Epoch 257/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 441.9944 - val_loss: 446.5246\n",
            "Epoch 258/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 441.8731 - val_loss: 445.9288\n",
            "Epoch 259/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 441.6455 - val_loss: 446.4308\n",
            "Epoch 260/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 441.5200 - val_loss: 445.1878\n",
            "Epoch 261/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 441.6016 - val_loss: 445.7425\n",
            "Epoch 262/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 440.8789 - val_loss: 445.0505\n",
            "Epoch 263/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 440.1956 - val_loss: 444.9106\n",
            "Epoch 264/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 441.0629 - val_loss: 448.0663\n",
            "Epoch 265/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 439.9588 - val_loss: 445.8799\n",
            "Epoch 266/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 439.9329 - val_loss: 443.6482\n",
            "Epoch 267/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 439.7043 - val_loss: 444.2830\n",
            "Epoch 268/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 439.3224 - val_loss: 442.8606\n",
            "Epoch 269/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 438.8986 - val_loss: 444.4962\n",
            "Epoch 270/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 438.4645 - val_loss: 445.4973\n",
            "Epoch 271/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 439.1747 - val_loss: 443.9461\n",
            "Epoch 272/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 438.4878 - val_loss: 442.7664\n",
            "Epoch 273/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 438.5091 - val_loss: 443.9379\n",
            "Epoch 274/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 437.4487 - val_loss: 442.4355\n",
            "Epoch 275/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 437.8703 - val_loss: 442.7975\n",
            "Epoch 276/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 437.4524 - val_loss: 442.7507\n",
            "Epoch 277/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 437.5246 - val_loss: 441.2927\n",
            "Epoch 278/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 437.0387 - val_loss: 442.5707\n",
            "Epoch 279/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 436.2461 - val_loss: 440.9005\n",
            "Epoch 280/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 436.4301 - val_loss: 443.6681\n",
            "Epoch 281/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 437.5574 - val_loss: 442.4293\n",
            "Epoch 282/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 435.8997 - val_loss: 443.9935\n",
            "Epoch 283/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 436.9440 - val_loss: 441.6550\n",
            "Epoch 284/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 435.7671 - val_loss: 440.4332\n",
            "Epoch 285/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 435.7191 - val_loss: 440.5185\n",
            "Epoch 286/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 434.8632 - val_loss: 441.5362\n",
            "Epoch 287/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 434.9343 - val_loss: 441.0017\n",
            "Epoch 288/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 435.0175 - val_loss: 439.9648\n",
            "Epoch 289/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 435.2524 - val_loss: 440.1172\n",
            "Epoch 290/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 434.5338 - val_loss: 439.5577\n",
            "Epoch 291/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 434.5931 - val_loss: 439.3798\n",
            "Epoch 292/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 434.3596 - val_loss: 440.1805\n",
            "Epoch 293/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 433.7990 - val_loss: 439.8150\n",
            "Epoch 294/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 433.6837 - val_loss: 440.2228\n",
            "Epoch 295/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 433.0461 - val_loss: 439.2635\n",
            "Epoch 296/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 433.1818 - val_loss: 438.4299\n",
            "Epoch 297/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 432.9598 - val_loss: 438.4925\n",
            "Epoch 298/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 432.7393 - val_loss: 438.5142\n",
            "Epoch 299/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 432.3770 - val_loss: 437.5325\n",
            "Epoch 300/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 432.1766 - val_loss: 436.8371\n",
            "Epoch 301/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 431.6863 - val_loss: 437.2606\n",
            "Epoch 302/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 431.3161 - val_loss: 437.2107\n",
            "Epoch 303/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 431.8688 - val_loss: 438.1767\n",
            "Epoch 304/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 431.0914 - val_loss: 438.6910\n",
            "Epoch 305/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 431.5495 - val_loss: 437.7631\n",
            "Epoch 306/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 430.2235 - val_loss: 438.7865\n",
            "Epoch 307/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 431.9383 - val_loss: 436.1561\n",
            "Epoch 308/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 430.9695 - val_loss: 436.8210\n",
            "Epoch 309/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 431.0830 - val_loss: 437.1905\n",
            "Epoch 310/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 430.1402 - val_loss: 436.0313\n",
            "Epoch 311/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 430.0778 - val_loss: 435.3295\n",
            "Epoch 312/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 429.3703 - val_loss: 437.1519\n",
            "Epoch 313/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 429.6617 - val_loss: 439.9301\n",
            "Epoch 314/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 429.0432 - val_loss: 435.3704\n",
            "Epoch 315/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 429.2831 - val_loss: 436.1188\n",
            "Epoch 316/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 428.9999 - val_loss: 435.1889\n",
            "Epoch 317/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 428.4991 - val_loss: 434.6758\n",
            "Epoch 318/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 428.4690 - val_loss: 435.5859\n",
            "Epoch 319/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 429.3795 - val_loss: 435.4476\n",
            "Epoch 320/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 428.4076 - val_loss: 435.1838\n",
            "Epoch 321/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 428.4138 - val_loss: 434.4783\n",
            "Epoch 322/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 428.2593 - val_loss: 433.9857\n",
            "Epoch 323/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 428.1299 - val_loss: 435.0497\n",
            "Epoch 324/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 427.2295 - val_loss: 435.0022\n",
            "Epoch 325/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 427.5555 - val_loss: 434.6772\n",
            "Epoch 326/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 426.8718 - val_loss: 434.2404\n",
            "Epoch 327/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 427.3121 - val_loss: 433.4448\n",
            "Epoch 328/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 426.6718 - val_loss: 434.6300\n",
            "Epoch 329/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 426.8855 - val_loss: 435.0908\n",
            "Epoch 330/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 427.0248 - val_loss: 433.0710\n",
            "Epoch 331/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 427.3085 - val_loss: 434.2730\n",
            "Epoch 332/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 425.8100 - val_loss: 435.6705\n",
            "Epoch 333/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 426.7776 - val_loss: 433.0790\n",
            "Epoch 334/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 426.0923 - val_loss: 432.1925\n",
            "Epoch 335/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 426.0587 - val_loss: 433.0993\n",
            "Epoch 336/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 426.0272 - val_loss: 432.4998\n",
            "Epoch 337/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 426.0152 - val_loss: 431.4605\n",
            "Epoch 338/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 425.5209 - val_loss: 432.3221\n",
            "Epoch 339/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 425.3366 - val_loss: 432.9519\n",
            "Epoch 340/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 424.5658 - val_loss: 431.0538\n",
            "Epoch 341/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 425.0421 - val_loss: 433.6539\n",
            "Epoch 342/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 424.8482 - val_loss: 431.4890\n",
            "Epoch 343/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 424.6036 - val_loss: 433.1765\n",
            "Epoch 344/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 424.6248 - val_loss: 431.4843\n",
            "Epoch 345/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 424.5600 - val_loss: 431.3225\n",
            "Epoch 346/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 424.0360 - val_loss: 431.5068\n",
            "Epoch 347/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 424.4716 - val_loss: 431.2759\n",
            "Epoch 348/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 423.6939 - val_loss: 432.0493\n",
            "Epoch 349/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 424.4799 - val_loss: 431.1541\n",
            "Epoch 350/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 423.2883 - val_loss: 435.3779\n",
            "Epoch 351/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 424.1128 - val_loss: 431.9771\n",
            "Epoch 352/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 423.6637 - val_loss: 431.9984\n",
            "Epoch 353/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 423.1622 - val_loss: 430.6650\n",
            "Epoch 354/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 423.6585 - val_loss: 429.8992\n",
            "Epoch 355/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 422.6777 - val_loss: 430.2722\n",
            "Epoch 356/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 422.7935 - val_loss: 429.9321\n",
            "Epoch 357/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 422.1694 - val_loss: 431.0379\n",
            "Epoch 358/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 422.8958 - val_loss: 430.1665\n",
            "Epoch 359/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 422.1585 - val_loss: 430.7909\n",
            "Epoch 360/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 421.5709 - val_loss: 431.6520\n",
            "Epoch 361/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 422.5728 - val_loss: 429.6942\n",
            "Epoch 362/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 421.7539 - val_loss: 428.4463\n",
            "Epoch 363/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 421.4640 - val_loss: 429.2471\n",
            "Epoch 364/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 421.6304 - val_loss: 429.4193\n",
            "Epoch 365/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 421.2351 - val_loss: 430.6825\n",
            "Epoch 366/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 421.7866 - val_loss: 428.7880\n",
            "Epoch 367/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 420.8693 - val_loss: 430.5186\n",
            "Epoch 368/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 422.4389 - val_loss: 428.6750\n",
            "Epoch 369/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 420.7729 - val_loss: 428.0899\n",
            "Epoch 370/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 420.6197 - val_loss: 428.6722\n",
            "Epoch 371/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 420.4313 - val_loss: 428.4561\n",
            "Epoch 372/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 420.5042 - val_loss: 427.0800\n",
            "Epoch 373/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 420.3177 - val_loss: 427.6159\n",
            "Epoch 374/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 420.3282 - val_loss: 427.8951\n",
            "Epoch 375/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 419.6065 - val_loss: 429.8210\n",
            "Epoch 376/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 419.6432 - val_loss: 426.5265\n",
            "Epoch 377/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 419.7938 - val_loss: 426.6602\n",
            "Epoch 378/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 419.5200 - val_loss: 428.1484\n",
            "Epoch 379/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 419.6513 - val_loss: 428.7764\n",
            "Epoch 380/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 419.3865 - val_loss: 428.0418\n",
            "Epoch 381/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 418.5557 - val_loss: 427.6827\n",
            "Epoch 382/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 418.9550 - val_loss: 426.8629\n",
            "Epoch 383/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 418.7393 - val_loss: 426.8715\n",
            "Epoch 384/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 418.8003 - val_loss: 427.3415\n",
            "Epoch 385/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 418.5585 - val_loss: 426.7314\n",
            "Epoch 386/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 418.5526 - val_loss: 426.3496\n",
            "Epoch 387/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 417.7192 - val_loss: 426.0241\n",
            "Epoch 388/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 418.1849 - val_loss: 427.0287\n",
            "Epoch 389/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 417.9860 - val_loss: 426.6227\n",
            "Epoch 390/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 417.4175 - val_loss: 426.0056\n",
            "Epoch 391/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 417.2963 - val_loss: 425.9863\n",
            "Epoch 392/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 417.5577 - val_loss: 425.8055\n",
            "Epoch 393/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 416.9142 - val_loss: 425.2109\n",
            "Epoch 394/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 417.1652 - val_loss: 425.7209\n",
            "Epoch 395/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 417.1788 - val_loss: 426.4128\n",
            "Epoch 396/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 416.5642 - val_loss: 426.0523\n",
            "Epoch 397/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 416.7201 - val_loss: 426.6904\n",
            "Epoch 398/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 416.7780 - val_loss: 426.8288\n",
            "Epoch 399/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 416.4433 - val_loss: 426.4022\n",
            "Epoch 400/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 416.1044 - val_loss: 425.7521\n",
            "Epoch 401/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 415.7548 - val_loss: 425.6894\n",
            "Epoch 402/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 416.6132 - val_loss: 424.4731\n",
            "Epoch 403/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 414.7283 - val_loss: 428.8642\n",
            "Epoch 404/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 415.4521 - val_loss: 425.9460\n",
            "Epoch 405/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 414.5423 - val_loss: 424.3668\n",
            "Epoch 406/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 414.7841 - val_loss: 424.7069\n",
            "Epoch 407/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 414.7984 - val_loss: 425.0898\n",
            "Epoch 408/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 414.5280 - val_loss: 425.6556\n",
            "Epoch 409/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 414.5412 - val_loss: 424.8841\n",
            "Epoch 410/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 414.6209 - val_loss: 427.9503\n",
            "Epoch 411/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 414.1265 - val_loss: 423.1793\n",
            "Epoch 412/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 414.1732 - val_loss: 425.1692\n",
            "Epoch 413/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 414.1641 - val_loss: 423.5218\n",
            "Epoch 414/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 414.2198 - val_loss: 424.2189\n",
            "Epoch 415/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 413.9456 - val_loss: 424.7302\n",
            "Epoch 416/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 413.6483 - val_loss: 425.7487\n",
            "Epoch 417/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 413.9379 - val_loss: 424.8288\n",
            "Epoch 418/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 414.2137 - val_loss: 423.9937\n",
            "Epoch 419/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 412.9633 - val_loss: 425.6881\n",
            "Epoch 420/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 413.4662 - val_loss: 423.9358\n",
            "Epoch 421/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 413.0512 - val_loss: 422.8595\n",
            "Epoch 422/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 412.7093 - val_loss: 423.9254\n",
            "Epoch 423/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 412.8361 - val_loss: 422.0952\n",
            "Epoch 424/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 413.0070 - val_loss: 426.0218\n",
            "Epoch 425/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 412.1926 - val_loss: 422.7082\n",
            "Epoch 426/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 412.3470 - val_loss: 422.9099\n",
            "Epoch 427/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 412.3875 - val_loss: 424.4409\n",
            "Epoch 428/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 412.0020 - val_loss: 423.6833\n",
            "Epoch 429/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 412.0899 - val_loss: 424.2999\n",
            "Epoch 430/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 411.8686 - val_loss: 422.8505\n",
            "Epoch 431/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 412.0631 - val_loss: 422.0733\n",
            "Epoch 432/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 411.5260 - val_loss: 423.0307\n",
            "Epoch 433/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 412.0063 - val_loss: 422.7986\n",
            "Epoch 434/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 411.1998 - val_loss: 423.8595\n",
            "Epoch 435/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 411.7419 - val_loss: 424.3355\n",
            "Epoch 436/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 411.2035 - val_loss: 421.8031\n",
            "Epoch 437/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 410.6629 - val_loss: 423.7232\n",
            "Epoch 438/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 411.2724 - val_loss: 422.7607\n",
            "Epoch 439/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 410.7054 - val_loss: 422.2198\n",
            "Epoch 440/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 410.2392 - val_loss: 421.7322\n",
            "Epoch 441/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 409.9478 - val_loss: 424.2061\n",
            "Epoch 442/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 411.7637 - val_loss: 421.7980\n",
            "Epoch 443/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 410.9522 - val_loss: 420.8271\n",
            "Epoch 444/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 409.9704 - val_loss: 421.7765\n",
            "Epoch 445/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 410.0807 - val_loss: 420.1213\n",
            "Epoch 446/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 410.3192 - val_loss: 420.9110\n",
            "Epoch 447/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 409.8523 - val_loss: 420.9828\n",
            "Epoch 448/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 408.9371 - val_loss: 422.9335\n",
            "Epoch 449/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 409.7246 - val_loss: 420.5834\n",
            "Epoch 450/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 409.5326 - val_loss: 420.9883\n",
            "Epoch 451/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 410.1122 - val_loss: 420.5089\n",
            "Epoch 452/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 409.2388 - val_loss: 422.1860\n",
            "Epoch 453/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 409.3194 - val_loss: 420.4977\n",
            "Epoch 454/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 409.0050 - val_loss: 421.4511\n",
            "Epoch 455/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 409.4059 - val_loss: 421.9238\n",
            "Epoch 456/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 408.7717 - val_loss: 420.2125\n",
            "Epoch 457/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 408.9931 - val_loss: 421.1342\n",
            "Epoch 458/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 408.8048 - val_loss: 421.2265\n",
            "Epoch 459/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 408.4007 - val_loss: 420.7916\n",
            "Epoch 460/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 408.3659 - val_loss: 420.6984\n",
            "Epoch 461/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 408.0728 - val_loss: 420.9892\n",
            "Epoch 462/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 407.9159 - val_loss: 420.2643\n",
            "Epoch 463/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 407.9515 - val_loss: 421.5288\n",
            "Epoch 464/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 407.9186 - val_loss: 418.9830\n",
            "Epoch 465/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 407.6956 - val_loss: 418.8054\n",
            "Epoch 466/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 407.0548 - val_loss: 420.8471\n",
            "Epoch 467/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 407.5787 - val_loss: 419.2836\n",
            "Epoch 468/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 407.7564 - val_loss: 418.8188\n",
            "Epoch 469/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 406.9822 - val_loss: 419.3058\n",
            "Epoch 470/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 406.9977 - val_loss: 418.9251\n",
            "Epoch 471/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 407.1018 - val_loss: 421.7506\n",
            "Epoch 472/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 406.7924 - val_loss: 423.9698\n",
            "Epoch 473/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 407.1673 - val_loss: 418.9501\n",
            "Epoch 474/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 406.5291 - val_loss: 419.0999\n",
            "Epoch 475/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 406.3944 - val_loss: 421.0587\n",
            "Epoch 476/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 406.4676 - val_loss: 421.7375\n",
            "Epoch 477/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 406.3110 - val_loss: 418.7168\n",
            "Epoch 478/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 405.6939 - val_loss: 420.9263\n",
            "Epoch 479/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 406.5027 - val_loss: 420.1115\n",
            "Epoch 480/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 405.9271 - val_loss: 419.1562\n",
            "Epoch 481/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 405.5648 - val_loss: 419.9005\n",
            "Epoch 482/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 406.5028 - val_loss: 418.8074\n",
            "Epoch 483/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 405.8701 - val_loss: 418.5000\n",
            "Epoch 484/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 405.4183 - val_loss: 419.4320\n",
            "Epoch 485/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 405.8324 - val_loss: 418.3344\n",
            "Epoch 486/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 405.7829 - val_loss: 417.3578\n",
            "Epoch 487/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 405.2266 - val_loss: 417.6287\n",
            "Epoch 488/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 405.3971 - val_loss: 419.1693\n",
            "Epoch 489/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 405.5082 - val_loss: 418.2696\n",
            "Epoch 490/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 405.1420 - val_loss: 420.1927\n",
            "Epoch 491/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 404.7817 - val_loss: 417.9478\n",
            "Epoch 492/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 404.9424 - val_loss: 417.5270\n",
            "Epoch 493/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 404.8724 - val_loss: 417.7096\n",
            "Epoch 494/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 404.6627 - val_loss: 417.3553\n",
            "Epoch 495/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 403.8141 - val_loss: 419.6639\n",
            "Epoch 496/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 404.1458 - val_loss: 417.0792\n",
            "Epoch 497/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 404.1934 - val_loss: 417.9191\n",
            "Epoch 498/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 404.6331 - val_loss: 416.1797\n",
            "Epoch 499/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 404.3392 - val_loss: 417.1631\n",
            "Epoch 500/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 403.3585 - val_loss: 418.3891\n",
            "Epoch 501/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 403.8975 - val_loss: 417.7629\n",
            "Epoch 502/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 403.5151 - val_loss: 415.5253\n",
            "Epoch 503/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 403.2366 - val_loss: 416.2518\n",
            "Epoch 504/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 403.4307 - val_loss: 415.4868\n",
            "Epoch 505/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 403.1455 - val_loss: 415.8182\n",
            "Epoch 506/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 403.2359 - val_loss: 415.4590\n",
            "Epoch 507/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 402.4341 - val_loss: 416.3615\n",
            "Epoch 508/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 402.5921 - val_loss: 418.6062\n",
            "Epoch 509/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 403.2116 - val_loss: 415.7498\n",
            "Epoch 510/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 402.3187 - val_loss: 419.1038\n",
            "Epoch 511/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 402.3014 - val_loss: 415.6554\n",
            "Epoch 512/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 402.2109 - val_loss: 415.1080\n",
            "Epoch 513/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 401.2347 - val_loss: 417.0037\n",
            "Epoch 514/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 401.6041 - val_loss: 417.2036\n",
            "Epoch 515/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 401.7055 - val_loss: 415.1638\n",
            "Epoch 516/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 401.5516 - val_loss: 415.9294\n",
            "Epoch 517/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 401.6735 - val_loss: 415.1137\n",
            "Epoch 518/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 401.6139 - val_loss: 416.3643\n",
            "Epoch 519/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 401.4809 - val_loss: 416.3008\n",
            "Epoch 520/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 401.0798 - val_loss: 415.1749\n",
            "Epoch 521/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 401.0368 - val_loss: 415.2243\n",
            "Epoch 522/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 400.7446 - val_loss: 414.7104\n",
            "Epoch 523/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 400.1549 - val_loss: 413.6179\n",
            "Epoch 524/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 400.3346 - val_loss: 413.1635\n",
            "Epoch 525/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 400.6607 - val_loss: 414.1733\n",
            "Epoch 526/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 400.4470 - val_loss: 413.3816\n",
            "Epoch 527/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 399.8749 - val_loss: 412.7546\n",
            "Epoch 528/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 400.0584 - val_loss: 412.4742\n",
            "Epoch 529/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 400.3848 - val_loss: 413.9283\n",
            "Epoch 530/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 399.2769 - val_loss: 413.9992\n",
            "Epoch 531/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 399.7549 - val_loss: 413.3762\n",
            "Epoch 532/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 400.2293 - val_loss: 412.7214\n",
            "Epoch 533/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 399.0286 - val_loss: 412.9120\n",
            "Epoch 534/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 398.8516 - val_loss: 412.8732\n",
            "Epoch 535/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 399.9558 - val_loss: 412.8222\n",
            "Epoch 536/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 399.4512 - val_loss: 412.4303\n",
            "Epoch 537/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 399.0605 - val_loss: 415.0919\n",
            "Epoch 538/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 398.7055 - val_loss: 413.0595\n",
            "Epoch 539/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 398.1665 - val_loss: 411.7906\n",
            "Epoch 540/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 398.0193 - val_loss: 412.7995\n",
            "Epoch 541/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 398.5552 - val_loss: 412.9248\n",
            "Epoch 542/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 397.9144 - val_loss: 412.2047\n",
            "Epoch 543/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 398.3316 - val_loss: 411.6190\n",
            "Epoch 544/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 398.4553 - val_loss: 410.9751\n",
            "Epoch 545/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 397.7064 - val_loss: 412.2090\n",
            "Epoch 546/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 397.7880 - val_loss: 413.7157\n",
            "Epoch 547/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 397.1643 - val_loss: 411.0320\n",
            "Epoch 548/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 397.3500 - val_loss: 411.9239\n",
            "Epoch 549/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 397.3360 - val_loss: 412.2668\n",
            "Epoch 550/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 397.2708 - val_loss: 411.9302\n",
            "Epoch 551/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 397.2008 - val_loss: 413.1795\n",
            "Epoch 552/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 396.6521 - val_loss: 411.1278\n",
            "Epoch 553/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 396.7597 - val_loss: 412.0421\n",
            "Epoch 554/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 396.9177 - val_loss: 411.6531\n",
            "Epoch 555/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 396.6968 - val_loss: 412.3990\n",
            "Epoch 556/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 396.0332 - val_loss: 413.3622\n",
            "Epoch 557/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 396.0815 - val_loss: 413.1743\n",
            "Epoch 558/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 395.9796 - val_loss: 411.0186\n",
            "Epoch 559/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 396.1915 - val_loss: 410.5869\n",
            "Epoch 560/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 396.3309 - val_loss: 412.5243\n",
            "Epoch 561/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 395.8259 - val_loss: 411.1801\n",
            "Epoch 562/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 395.3843 - val_loss: 412.5606\n",
            "Epoch 563/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 396.3195 - val_loss: 409.7751\n",
            "Epoch 564/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 395.7603 - val_loss: 409.4405\n",
            "Epoch 565/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 395.7008 - val_loss: 412.5638\n",
            "Epoch 566/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 396.1195 - val_loss: 411.1577\n",
            "Epoch 567/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 395.1267 - val_loss: 410.2154\n",
            "Epoch 568/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 395.2963 - val_loss: 409.8956\n",
            "Epoch 569/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 394.3742 - val_loss: 413.4000\n",
            "Epoch 570/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 394.4843 - val_loss: 409.9099\n",
            "Epoch 571/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 394.8024 - val_loss: 410.9933\n",
            "Epoch 572/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 394.6065 - val_loss: 409.5775\n",
            "Epoch 573/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 394.0119 - val_loss: 409.6023\n",
            "Epoch 574/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 394.9194 - val_loss: 411.2673\n",
            "Epoch 575/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 394.9622 - val_loss: 409.3447\n",
            "Epoch 576/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 393.7287 - val_loss: 411.3320\n",
            "Epoch 577/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 394.2561 - val_loss: 409.6365\n",
            "Epoch 578/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 394.3575 - val_loss: 409.1269\n",
            "Epoch 579/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 393.7460 - val_loss: 408.9482\n",
            "Epoch 580/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 393.7464 - val_loss: 409.6786\n",
            "Epoch 581/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 393.6089 - val_loss: 411.3578\n",
            "Epoch 582/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 393.7996 - val_loss: 409.3336\n",
            "Epoch 583/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 393.7608 - val_loss: 411.4433\n",
            "Epoch 584/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 394.2935 - val_loss: 409.4428\n",
            "Epoch 585/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 393.5221 - val_loss: 410.0374\n",
            "Epoch 586/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 393.6434 - val_loss: 409.0731\n",
            "Epoch 587/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 393.4016 - val_loss: 409.8244\n",
            "Epoch 588/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 392.8734 - val_loss: 408.1187\n",
            "Epoch 589/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 392.4191 - val_loss: 409.8722\n",
            "Epoch 590/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 392.6817 - val_loss: 408.9745\n",
            "Epoch 591/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 392.4278 - val_loss: 408.3633\n",
            "Epoch 592/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 392.1033 - val_loss: 408.5222\n",
            "Epoch 593/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 392.2037 - val_loss: 407.6521\n",
            "Epoch 594/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 391.9441 - val_loss: 409.0539\n",
            "Epoch 595/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 392.8236 - val_loss: 407.9253\n",
            "Epoch 596/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 392.1043 - val_loss: 407.9372\n",
            "Epoch 597/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 392.5597 - val_loss: 407.8115\n",
            "Epoch 598/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 392.0336 - val_loss: 407.0882\n",
            "Epoch 599/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 391.7796 - val_loss: 407.9091\n",
            "Epoch 600/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 391.2090 - val_loss: 406.9543\n",
            "Epoch 601/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 391.3729 - val_loss: 407.2242\n",
            "Epoch 602/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 391.1039 - val_loss: 409.7039\n",
            "Epoch 603/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 391.3687 - val_loss: 407.8411\n",
            "Epoch 604/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 391.3006 - val_loss: 406.5681\n",
            "Epoch 605/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 391.9546 - val_loss: 407.7216\n",
            "Epoch 606/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 391.4592 - val_loss: 408.3562\n",
            "Epoch 607/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 391.1576 - val_loss: 406.7244\n",
            "Epoch 608/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 390.6873 - val_loss: 406.3564\n",
            "Epoch 609/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 390.7836 - val_loss: 408.0711\n",
            "Epoch 610/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 391.5350 - val_loss: 406.4887\n",
            "Epoch 611/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 389.7140 - val_loss: 410.5647\n",
            "Epoch 612/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 391.1693 - val_loss: 407.5938\n",
            "Epoch 613/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 389.9912 - val_loss: 407.8636\n",
            "Epoch 614/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 390.5572 - val_loss: 406.5529\n",
            "Epoch 615/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 390.0883 - val_loss: 408.1018\n",
            "Epoch 616/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 390.7033 - val_loss: 406.0024\n",
            "Epoch 617/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 389.8838 - val_loss: 410.0365\n",
            "Epoch 618/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 389.7471 - val_loss: 407.0213\n",
            "Epoch 619/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 389.7896 - val_loss: 405.7862\n",
            "Epoch 620/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 390.5513 - val_loss: 407.7854\n",
            "Epoch 621/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 390.1524 - val_loss: 405.8264\n",
            "Epoch 622/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 389.5228 - val_loss: 408.1101\n",
            "Epoch 623/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 389.3079 - val_loss: 406.6558\n",
            "Epoch 624/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 389.2436 - val_loss: 406.3065\n",
            "Epoch 625/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 389.1503 - val_loss: 410.4213\n",
            "Epoch 626/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 389.8234 - val_loss: 406.7254\n",
            "Epoch 627/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 389.0450 - val_loss: 404.9650\n",
            "Epoch 628/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 388.6507 - val_loss: 407.5232\n",
            "Epoch 629/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 388.4035 - val_loss: 406.0394\n",
            "Epoch 630/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 388.6772 - val_loss: 405.0233\n",
            "Epoch 631/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 388.6497 - val_loss: 410.0346\n",
            "Epoch 632/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 387.9211 - val_loss: 406.3495\n",
            "Epoch 633/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 388.8481 - val_loss: 405.5750\n",
            "Epoch 634/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 388.6910 - val_loss: 405.2952\n",
            "Epoch 635/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 388.5279 - val_loss: 405.6823\n",
            "Epoch 636/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 388.2483 - val_loss: 406.9119\n",
            "Epoch 637/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 388.7570 - val_loss: 405.7645\n",
            "Epoch 638/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 388.3126 - val_loss: 408.6701\n",
            "Epoch 639/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 389.2298 - val_loss: 405.8779\n",
            "Epoch 640/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 387.0285 - val_loss: 405.6866\n",
            "Epoch 641/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 388.1971 - val_loss: 407.3280\n",
            "Epoch 642/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 387.8771 - val_loss: 405.9822\n",
            "Epoch 643/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 388.2669 - val_loss: 405.0593\n",
            "Epoch 644/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 387.6788 - val_loss: 404.2155\n",
            "Epoch 645/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 387.4124 - val_loss: 404.8726\n",
            "Epoch 646/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 386.9005 - val_loss: 405.9670\n",
            "Epoch 647/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 387.2625 - val_loss: 404.5325\n",
            "Epoch 648/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 387.7777 - val_loss: 403.6652\n",
            "Epoch 649/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 386.5446 - val_loss: 404.2852\n",
            "Epoch 650/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 386.9879 - val_loss: 404.2749\n",
            "Epoch 651/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 386.8064 - val_loss: 405.6290\n",
            "Epoch 652/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 386.8306 - val_loss: 406.2716\n",
            "Epoch 653/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 386.9696 - val_loss: 404.6344\n",
            "Epoch 654/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 386.6421 - val_loss: 404.4138\n",
            "Epoch 655/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 385.6676 - val_loss: 406.0527\n",
            "Epoch 656/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 386.6089 - val_loss: 405.4847\n",
            "Epoch 657/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 386.4833 - val_loss: 404.5934\n",
            "Epoch 658/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 386.3846 - val_loss: 404.2938\n",
            "Epoch 659/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 386.0381 - val_loss: 403.2181\n",
            "Epoch 660/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 386.0652 - val_loss: 405.2808\n",
            "Epoch 661/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 385.5956 - val_loss: 405.9275\n",
            "Epoch 662/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 385.8197 - val_loss: 404.8907\n",
            "Epoch 663/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 385.8517 - val_loss: 403.7331\n",
            "Epoch 664/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 385.9406 - val_loss: 404.4162\n",
            "Epoch 665/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 386.2475 - val_loss: 403.3870\n",
            "Epoch 666/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 385.9600 - val_loss: 403.6364\n",
            "Epoch 667/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 385.5765 - val_loss: 403.4684\n",
            "Epoch 668/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 384.7478 - val_loss: 407.7164\n",
            "Epoch 669/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 385.8779 - val_loss: 402.6382\n",
            "Epoch 670/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 385.3898 - val_loss: 404.3860\n",
            "Epoch 671/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 385.0959 - val_loss: 402.5791\n",
            "Epoch 672/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 384.2285 - val_loss: 405.5798\n",
            "Epoch 673/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 385.6151 - val_loss: 404.7628\n",
            "Epoch 674/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 385.5358 - val_loss: 404.3749\n",
            "Epoch 675/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 385.4614 - val_loss: 404.6148\n",
            "Epoch 676/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 386.0186 - val_loss: 402.6980\n",
            "Epoch 677/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 384.5792 - val_loss: 403.0149\n",
            "Epoch 678/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 384.4512 - val_loss: 402.5062\n",
            "Epoch 679/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 383.8742 - val_loss: 405.2825\n",
            "Epoch 680/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 384.8658 - val_loss: 403.3549\n",
            "Epoch 681/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 384.5192 - val_loss: 403.5679\n",
            "Epoch 682/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 384.1036 - val_loss: 404.1745\n",
            "Epoch 683/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 384.7927 - val_loss: 404.4874\n",
            "Epoch 684/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 383.8340 - val_loss: 404.3554\n",
            "Epoch 685/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 384.4655 - val_loss: 401.6243\n",
            "Epoch 686/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 383.7469 - val_loss: 403.7520\n",
            "Epoch 687/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 384.0151 - val_loss: 402.8851\n",
            "Epoch 688/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 383.3511 - val_loss: 404.6100\n",
            "Epoch 689/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 383.6509 - val_loss: 402.3492\n",
            "Epoch 690/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 383.7800 - val_loss: 402.4431\n",
            "Epoch 691/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 383.5840 - val_loss: 401.7889\n",
            "Epoch 692/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 383.2254 - val_loss: 401.8297\n",
            "Epoch 693/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 383.3008 - val_loss: 405.0711\n",
            "Epoch 694/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 383.6254 - val_loss: 402.2324\n",
            "Epoch 695/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 382.8503 - val_loss: 400.9571\n",
            "Epoch 696/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 383.2928 - val_loss: 402.5648\n",
            "Epoch 697/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 382.7329 - val_loss: 403.8857\n",
            "Epoch 698/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 383.4737 - val_loss: 401.9478\n",
            "Epoch 699/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 382.9427 - val_loss: 402.3200\n",
            "Epoch 700/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 382.5696 - val_loss: 401.4170\n",
            "Epoch 701/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 382.4351 - val_loss: 403.2551\n",
            "Epoch 702/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 382.4711 - val_loss: 401.6245\n",
            "Epoch 703/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 381.9025 - val_loss: 402.6931\n",
            "Epoch 704/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 383.2100 - val_loss: 404.1341\n",
            "Epoch 705/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 382.5374 - val_loss: 401.8066\n",
            "Epoch 706/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 382.3818 - val_loss: 400.5430\n",
            "Epoch 707/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 381.6507 - val_loss: 403.0592\n",
            "Epoch 708/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 383.0615 - val_loss: 402.5757\n",
            "Epoch 709/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 381.5542 - val_loss: 402.3282\n",
            "Epoch 710/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 382.2157 - val_loss: 401.2521\n",
            "Epoch 711/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 382.4740 - val_loss: 402.2241\n",
            "Epoch 712/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 382.0532 - val_loss: 400.3224\n",
            "Epoch 713/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 381.5381 - val_loss: 401.0171\n",
            "Epoch 714/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 381.5186 - val_loss: 401.1189\n",
            "Epoch 715/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 381.9952 - val_loss: 400.5085\n",
            "Epoch 716/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 381.5568 - val_loss: 401.9917\n",
            "Epoch 717/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 381.0441 - val_loss: 401.3697\n",
            "Epoch 718/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 380.8010 - val_loss: 401.2554\n",
            "Epoch 719/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 381.1516 - val_loss: 400.7622\n",
            "Epoch 720/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 380.6514 - val_loss: 404.3177\n",
            "Epoch 721/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 381.1228 - val_loss: 401.0662\n",
            "Epoch 722/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 380.7451 - val_loss: 401.5633\n",
            "Epoch 723/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 380.5862 - val_loss: 404.8786\n",
            "Epoch 724/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 380.6464 - val_loss: 402.4253\n",
            "Epoch 725/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 382.3786 - val_loss: 402.5113\n",
            "Epoch 726/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 380.9904 - val_loss: 401.2006\n",
            "Epoch 727/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 381.0691 - val_loss: 401.2040\n",
            "Epoch 728/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 380.0049 - val_loss: 400.5886\n",
            "Epoch 729/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 380.7386 - val_loss: 399.9362\n",
            "Epoch 730/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 380.1706 - val_loss: 400.7219\n",
            "Epoch 731/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 380.3979 - val_loss: 401.1825\n",
            "Epoch 732/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 380.2064 - val_loss: 400.0707\n",
            "Epoch 733/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 379.5435 - val_loss: 401.5127\n",
            "Epoch 734/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 381.1471 - val_loss: 400.9839\n",
            "Epoch 735/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 380.5946 - val_loss: 401.1700\n",
            "Epoch 736/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 379.5256 - val_loss: 401.3583\n",
            "Epoch 737/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 379.8594 - val_loss: 400.1997\n",
            "Epoch 738/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 379.8632 - val_loss: 400.4751\n",
            "Epoch 739/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 379.5413 - val_loss: 401.4341\n",
            "Epoch 740/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 379.8701 - val_loss: 400.6879\n",
            "Epoch 741/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 379.4560 - val_loss: 400.3918\n",
            "Epoch 742/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 379.2137 - val_loss: 400.3331\n",
            "Epoch 743/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 380.1533 - val_loss: 399.3425\n",
            "Epoch 744/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 378.8605 - val_loss: 399.0103\n",
            "Epoch 745/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 379.7355 - val_loss: 400.0256\n",
            "Epoch 746/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 379.0717 - val_loss: 398.8710\n",
            "Epoch 747/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 378.8519 - val_loss: 400.1713\n",
            "Epoch 748/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 379.6398 - val_loss: 401.0923\n",
            "Epoch 749/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.9931 - val_loss: 403.6378\n",
            "Epoch 750/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 379.7315 - val_loss: 398.4401\n",
            "Epoch 751/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 378.6357 - val_loss: 400.4328\n",
            "Epoch 752/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 378.2550 - val_loss: 400.4107\n",
            "Epoch 753/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 379.1672 - val_loss: 399.1916\n",
            "Epoch 754/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.6722 - val_loss: 399.1886\n",
            "Epoch 755/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.8940 - val_loss: 399.5204\n",
            "Epoch 756/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 379.0057 - val_loss: 398.5782\n",
            "Epoch 757/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 378.0944 - val_loss: 399.7425\n",
            "Epoch 758/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.6849 - val_loss: 398.1288\n",
            "Epoch 759/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.8611 - val_loss: 399.3452\n",
            "Epoch 760/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 378.6208 - val_loss: 400.6078\n",
            "Epoch 761/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 378.8280 - val_loss: 399.4754\n",
            "Epoch 762/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.8038 - val_loss: 397.7892\n",
            "Epoch 763/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.1112 - val_loss: 400.3717\n",
            "Epoch 764/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 378.3323 - val_loss: 398.2024\n",
            "Epoch 765/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 378.4054 - val_loss: 399.8179\n",
            "Epoch 766/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.6384 - val_loss: 397.5431\n",
            "Epoch 767/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 376.9371 - val_loss: 398.1243\n",
            "Epoch 768/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 378.0713 - val_loss: 399.7639\n",
            "Epoch 769/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.2489 - val_loss: 398.3976\n",
            "Epoch 770/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.1062 - val_loss: 397.4573\n",
            "Epoch 771/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.9164 - val_loss: 399.2975\n",
            "Epoch 772/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 378.2672 - val_loss: 398.1943\n",
            "Epoch 773/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.6034 - val_loss: 398.2414\n",
            "Epoch 774/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.1161 - val_loss: 397.6278\n",
            "Epoch 775/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.2662 - val_loss: 397.1089\n",
            "Epoch 776/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.6660 - val_loss: 397.4135\n",
            "Epoch 777/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 377.2729 - val_loss: 397.5774\n",
            "Epoch 778/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 377.0622 - val_loss: 400.2662\n",
            "Epoch 779/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.8243 - val_loss: 397.8343\n",
            "Epoch 780/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.0998 - val_loss: 397.9329\n",
            "Epoch 781/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.5390 - val_loss: 398.5201\n",
            "Epoch 782/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.6256 - val_loss: 398.0392\n",
            "Epoch 783/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.9250 - val_loss: 397.4699\n",
            "Epoch 784/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.7025 - val_loss: 399.8725\n",
            "Epoch 785/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.9164 - val_loss: 397.1832\n",
            "Epoch 786/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 375.5215 - val_loss: 397.9978\n",
            "Epoch 787/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.4291 - val_loss: 397.9918\n",
            "Epoch 788/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.1058 - val_loss: 396.3270\n",
            "Epoch 789/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.7082 - val_loss: 396.9319\n",
            "Epoch 790/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 375.6245 - val_loss: 398.1453\n",
            "Epoch 791/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 375.7607 - val_loss: 396.9813\n",
            "Epoch 792/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 375.7012 - val_loss: 397.6910\n",
            "Epoch 793/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 375.2947 - val_loss: 397.1794\n",
            "Epoch 794/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.0248 - val_loss: 397.3582\n",
            "Epoch 795/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 376.0885 - val_loss: 397.4388\n",
            "Epoch 796/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 375.9406 - val_loss: 398.4484\n",
            "Epoch 797/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 375.0767 - val_loss: 401.4823\n",
            "Epoch 798/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 375.7872 - val_loss: 396.4197\n",
            "Epoch 799/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 375.1695 - val_loss: 397.4903\n",
            "Epoch 800/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 375.2973 - val_loss: 398.6492\n",
            "Epoch 801/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 375.3772 - val_loss: 396.2789\n",
            "Epoch 802/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 375.0947 - val_loss: 396.8587\n",
            "Epoch 803/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 375.6610 - val_loss: 396.6216\n",
            "Epoch 804/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 374.3795 - val_loss: 398.1246\n",
            "Epoch 805/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.8523 - val_loss: 395.8746\n",
            "Epoch 806/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 375.3045 - val_loss: 399.4778\n",
            "Epoch 807/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.8768 - val_loss: 395.7781\n",
            "Epoch 808/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.5470 - val_loss: 396.1655\n",
            "Epoch 809/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.1865 - val_loss: 396.3347\n",
            "Epoch 810/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.2626 - val_loss: 395.6628\n",
            "Epoch 811/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.4845 - val_loss: 395.0499\n",
            "Epoch 812/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.0584 - val_loss: 397.2587\n",
            "Epoch 813/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.7220 - val_loss: 396.1314\n",
            "Epoch 814/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.1094 - val_loss: 394.8486\n",
            "Epoch 815/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 375.9161 - val_loss: 395.5033\n",
            "Epoch 816/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.0203 - val_loss: 396.4850\n",
            "Epoch 817/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.1922 - val_loss: 395.6506\n",
            "Epoch 818/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.0410 - val_loss: 395.5698\n",
            "Epoch 819/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.0041 - val_loss: 395.7039\n",
            "Epoch 820/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 373.8483 - val_loss: 399.2934\n",
            "Epoch 821/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 374.0655 - val_loss: 395.5938\n",
            "Epoch 822/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 373.9684 - val_loss: 394.7564\n",
            "Epoch 823/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 373.4242 - val_loss: 399.5021\n",
            "Epoch 824/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 373.6950 - val_loss: 395.0428\n",
            "Epoch 825/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.9445 - val_loss: 396.5806\n",
            "Epoch 826/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 373.5026 - val_loss: 398.8890\n",
            "Epoch 827/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 373.2374 - val_loss: 397.6450\n",
            "Epoch 828/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 373.5277 - val_loss: 395.5971\n",
            "Epoch 829/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 373.7038 - val_loss: 395.1432\n",
            "Epoch 830/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 373.3687 - val_loss: 396.6951\n",
            "Epoch 831/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.8193 - val_loss: 395.0305\n",
            "Epoch 832/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.9835 - val_loss: 394.9535\n",
            "Epoch 833/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 373.0544 - val_loss: 395.0128\n",
            "Epoch 834/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 373.3159 - val_loss: 395.9776\n",
            "Epoch 835/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 373.1047 - val_loss: 393.6747\n",
            "Epoch 836/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.7337 - val_loss: 399.3721\n",
            "Epoch 837/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 372.9142 - val_loss: 395.0027\n",
            "Epoch 838/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.5093 - val_loss: 397.8090\n",
            "Epoch 839/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 373.3391 - val_loss: 393.7830\n",
            "Epoch 840/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.2394 - val_loss: 395.5784\n",
            "Epoch 841/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 372.2257 - val_loss: 396.6747\n",
            "Epoch 842/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 373.0670 - val_loss: 394.5913\n",
            "Epoch 843/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.7970 - val_loss: 399.3036\n",
            "Epoch 844/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.3620 - val_loss: 393.7583\n",
            "Epoch 845/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.3094 - val_loss: 395.2041\n",
            "Epoch 846/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.4475 - val_loss: 393.8950\n",
            "Epoch 847/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.0442 - val_loss: 393.2445\n",
            "Epoch 848/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.3031 - val_loss: 393.9669\n",
            "Epoch 849/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.9439 - val_loss: 394.6166\n",
            "Epoch 850/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 372.5388 - val_loss: 393.7759\n",
            "Epoch 851/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.5943 - val_loss: 393.1846\n",
            "Epoch 852/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 371.5728 - val_loss: 393.3911\n",
            "Epoch 853/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 371.7324 - val_loss: 392.2237\n",
            "Epoch 854/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.2669 - val_loss: 395.6401\n",
            "Epoch 855/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.6442 - val_loss: 392.5493\n",
            "Epoch 856/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 371.5396 - val_loss: 395.7791\n",
            "Epoch 857/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.2124 - val_loss: 392.7722\n",
            "Epoch 858/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.0671 - val_loss: 391.9227\n",
            "Epoch 859/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.7982 - val_loss: 392.2252\n",
            "Epoch 860/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.1383 - val_loss: 393.6552\n",
            "Epoch 861/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 372.2899 - val_loss: 394.7318\n",
            "Epoch 862/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 370.8460 - val_loss: 392.0034\n",
            "Epoch 863/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.4557 - val_loss: 393.3022\n",
            "Epoch 864/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.0681 - val_loss: 394.6970\n",
            "Epoch 865/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 370.9856 - val_loss: 393.1703\n",
            "Epoch 866/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 370.1268 - val_loss: 395.5324\n",
            "Epoch 867/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 370.7538 - val_loss: 392.8958\n",
            "Epoch 868/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.2858 - val_loss: 392.5177\n",
            "Epoch 869/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 371.0090 - val_loss: 394.8987\n",
            "Epoch 870/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 370.8206 - val_loss: 392.6346\n",
            "Epoch 871/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.0750 - val_loss: 396.8704\n",
            "Epoch 872/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 371.0038 - val_loss: 393.3718\n",
            "Epoch 873/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 370.3815 - val_loss: 392.3583\n",
            "Epoch 874/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 370.6412 - val_loss: 393.6805\n",
            "Epoch 875/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 369.7382 - val_loss: 392.1401\n",
            "Epoch 876/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 370.0746 - val_loss: 392.5472\n",
            "Epoch 877/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 370.4474 - val_loss: 392.4437\n",
            "Epoch 878/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 370.1634 - val_loss: 391.3038\n",
            "Epoch 879/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 369.9449 - val_loss: 391.9106\n",
            "Epoch 880/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 370.1988 - val_loss: 393.0784\n",
            "Epoch 881/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 369.9808 - val_loss: 393.6515\n",
            "Epoch 882/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 369.5980 - val_loss: 391.4468\n",
            "Epoch 883/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 369.5825 - val_loss: 393.0994\n",
            "Epoch 884/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 369.5413 - val_loss: 394.4466\n",
            "Epoch 885/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 369.8915 - val_loss: 392.3344\n",
            "Epoch 886/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 369.2044 - val_loss: 391.6836\n",
            "Epoch 887/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 369.5819 - val_loss: 392.2461\n",
            "Epoch 888/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 369.1396 - val_loss: 391.3169\n",
            "Epoch 889/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.5676 - val_loss: 393.3354\n",
            "Epoch 890/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 369.1423 - val_loss: 390.9970\n",
            "Epoch 891/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.6755 - val_loss: 391.3505\n",
            "Epoch 892/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 369.5784 - val_loss: 390.6896\n",
            "Epoch 893/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.9716 - val_loss: 390.6306\n",
            "Epoch 894/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.3596 - val_loss: 391.6256\n",
            "Epoch 895/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.1105 - val_loss: 390.9787\n",
            "Epoch 896/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 370.2597 - val_loss: 391.9000\n",
            "Epoch 897/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 369.0951 - val_loss: 390.0465\n",
            "Epoch 898/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.7394 - val_loss: 391.1343\n",
            "Epoch 899/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.2570 - val_loss: 391.2566\n",
            "Epoch 900/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.4795 - val_loss: 391.3157\n",
            "Epoch 901/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.9962 - val_loss: 392.2488\n",
            "Epoch 902/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.9537 - val_loss: 390.4226\n",
            "Epoch 903/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.4860 - val_loss: 390.5338\n",
            "Epoch 904/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.3069 - val_loss: 391.1779\n",
            "Epoch 905/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.1841 - val_loss: 391.1006\n",
            "Epoch 906/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.1712 - val_loss: 390.2437\n",
            "Epoch 907/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.8329 - val_loss: 390.3014\n",
            "Epoch 908/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.3639 - val_loss: 389.7889\n",
            "Epoch 909/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 367.9221 - val_loss: 389.8210\n",
            "Epoch 910/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.1238 - val_loss: 389.9042\n",
            "Epoch 911/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.1796 - val_loss: 392.2451\n",
            "Epoch 912/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.3672 - val_loss: 391.1923\n",
            "Epoch 913/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.7311 - val_loss: 390.9778\n",
            "Epoch 914/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.9244 - val_loss: 390.6927\n",
            "Epoch 915/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.0131 - val_loss: 390.7767\n",
            "Epoch 916/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.3448 - val_loss: 390.4333\n",
            "Epoch 917/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.2370 - val_loss: 389.5594\n",
            "Epoch 918/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.9824 - val_loss: 389.1830\n",
            "Epoch 919/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.2856 - val_loss: 389.5512\n",
            "Epoch 920/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.5366 - val_loss: 391.1078\n",
            "Epoch 921/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 368.1257 - val_loss: 390.0149\n",
            "Epoch 922/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 366.8653 - val_loss: 390.7895\n",
            "Epoch 923/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 366.4155 - val_loss: 391.1270\n",
            "Epoch 924/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.0496 - val_loss: 392.0632\n",
            "Epoch 925/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.0533 - val_loss: 390.3722\n",
            "Epoch 926/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.1553 - val_loss: 390.0946\n",
            "Epoch 927/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 367.3530 - val_loss: 388.8175\n",
            "Epoch 928/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 366.5984 - val_loss: 389.0766\n",
            "Epoch 929/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 366.6278 - val_loss: 389.8662\n",
            "Epoch 930/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 366.5600 - val_loss: 390.3667\n",
            "Epoch 931/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.8542 - val_loss: 391.1943\n",
            "Epoch 932/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 366.6480 - val_loss: 389.4851\n",
            "Epoch 933/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 366.5704 - val_loss: 390.5997\n",
            "Epoch 934/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 366.6940 - val_loss: 390.2948\n",
            "Epoch 935/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 367.3061 - val_loss: 389.1084\n",
            "Epoch 936/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 366.1190 - val_loss: 389.5850\n",
            "Epoch 937/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 366.8190 - val_loss: 389.9261\n",
            "Epoch 938/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 366.5249 - val_loss: 389.5495\n",
            "Epoch 939/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.5064 - val_loss: 393.4792\n",
            "Epoch 940/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.6429 - val_loss: 391.7993\n",
            "Epoch 941/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.6310 - val_loss: 390.2945\n",
            "Epoch 942/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 366.2979 - val_loss: 389.0404\n",
            "Epoch 943/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.9183 - val_loss: 390.5148\n",
            "Epoch 944/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.1887 - val_loss: 389.5704\n",
            "Epoch 945/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.5861 - val_loss: 393.2721\n",
            "Epoch 946/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.6987 - val_loss: 388.5213\n",
            "Epoch 947/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.6600 - val_loss: 390.3531\n",
            "Epoch 948/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.9876 - val_loss: 389.3758\n",
            "Epoch 949/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.2477 - val_loss: 388.2852\n",
            "Epoch 950/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.0811 - val_loss: 391.0550\n",
            "Epoch 951/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 366.1562 - val_loss: 389.9626\n",
            "Epoch 952/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.6295 - val_loss: 390.5166\n",
            "Epoch 953/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.3469 - val_loss: 389.2904\n",
            "Epoch 954/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.2458 - val_loss: 388.2150\n",
            "Epoch 955/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.3725 - val_loss: 390.5369\n",
            "Epoch 956/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.2422 - val_loss: 388.8288\n",
            "Epoch 957/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.5075 - val_loss: 387.7924\n",
            "Epoch 958/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.4521 - val_loss: 389.1206\n",
            "Epoch 959/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.5145 - val_loss: 388.4932\n",
            "Epoch 960/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.7667 - val_loss: 388.0075\n",
            "Epoch 961/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.9840 - val_loss: 390.4578\n",
            "Epoch 962/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.0613 - val_loss: 389.6786\n",
            "Epoch 963/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 365.1891 - val_loss: 387.6931\n",
            "Epoch 964/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.8584 - val_loss: 391.1401\n",
            "Epoch 965/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.8534 - val_loss: 390.4215\n",
            "Epoch 966/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.6219 - val_loss: 388.4009\n",
            "Epoch 967/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.6216 - val_loss: 388.8482\n",
            "Epoch 968/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 364.5392 - val_loss: 387.2616\n",
            "Epoch 969/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 363.7988 - val_loss: 390.5620\n",
            "Epoch 970/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.0835 - val_loss: 388.2923\n",
            "Epoch 971/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.0193 - val_loss: 389.3981\n",
            "Epoch 972/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.2938 - val_loss: 391.1043\n",
            "Epoch 973/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 364.3447 - val_loss: 388.8290\n",
            "Epoch 974/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.1622 - val_loss: 389.1222\n",
            "Epoch 975/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.1607 - val_loss: 388.0906\n",
            "Epoch 976/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.9775 - val_loss: 388.5562\n",
            "Epoch 977/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.0845 - val_loss: 388.1244\n",
            "Epoch 978/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.5836 - val_loss: 387.3675\n",
            "Epoch 979/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.2735 - val_loss: 387.4563\n",
            "Epoch 980/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.3384 - val_loss: 386.8924\n",
            "Epoch 981/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 363.4329 - val_loss: 387.0550\n",
            "Epoch 982/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 364.5768 - val_loss: 387.6810\n",
            "Epoch 983/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.0721 - val_loss: 387.4120\n",
            "Epoch 984/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.8386 - val_loss: 392.3512\n",
            "Epoch 985/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.3939 - val_loss: 386.9685\n",
            "Epoch 986/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.7402 - val_loss: 388.5924\n",
            "Epoch 987/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.2262 - val_loss: 386.7253\n",
            "Epoch 988/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.2856 - val_loss: 387.7328\n",
            "Epoch 989/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.0068 - val_loss: 389.9489\n",
            "Epoch 990/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.8897 - val_loss: 387.2598\n",
            "Epoch 991/2500\n",
            "139/139 [==============================] - 1s 4ms/step - loss: 362.5051 - val_loss: 388.3375\n",
            "Epoch 992/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.6595 - val_loss: 388.0486\n",
            "Epoch 993/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.3589 - val_loss: 388.4377\n",
            "Epoch 994/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.9429 - val_loss: 388.8461\n",
            "Epoch 995/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.0133 - val_loss: 388.3120\n",
            "Epoch 996/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.7052 - val_loss: 386.0381\n",
            "Epoch 997/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.4899 - val_loss: 387.5992\n",
            "Epoch 998/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.4155 - val_loss: 387.5502\n",
            "Epoch 999/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.5007 - val_loss: 390.2303\n",
            "Epoch 1000/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 363.3745 - val_loss: 387.9396\n",
            "Epoch 1001/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.5486 - val_loss: 388.8803\n",
            "Epoch 1002/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.9913 - val_loss: 386.7983\n",
            "Epoch 1003/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.1836 - val_loss: 385.5854\n",
            "Epoch 1004/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.8629 - val_loss: 386.2224\n",
            "Epoch 1005/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.1134 - val_loss: 386.7825\n",
            "Epoch 1006/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.7864 - val_loss: 385.7048\n",
            "Epoch 1007/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.2820 - val_loss: 386.7150\n",
            "Epoch 1008/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.8398 - val_loss: 386.2013\n",
            "Epoch 1009/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.6762 - val_loss: 385.1097\n",
            "Epoch 1010/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.5544 - val_loss: 384.6867\n",
            "Epoch 1011/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.9046 - val_loss: 386.5664\n",
            "Epoch 1012/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.8930 - val_loss: 386.5906\n",
            "Epoch 1013/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 362.0477 - val_loss: 387.2290\n",
            "Epoch 1014/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.8665 - val_loss: 386.0607\n",
            "Epoch 1015/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.9929 - val_loss: 385.8371\n",
            "Epoch 1016/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.7660 - val_loss: 387.3358\n",
            "Epoch 1017/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.0350 - val_loss: 385.7142\n",
            "Epoch 1018/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.0706 - val_loss: 386.9840\n",
            "Epoch 1019/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.9441 - val_loss: 384.8679\n",
            "Epoch 1020/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.2753 - val_loss: 385.0774\n",
            "Epoch 1021/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.9889 - val_loss: 384.8963\n",
            "Epoch 1022/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.9510 - val_loss: 386.2870\n",
            "Epoch 1023/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.7556 - val_loss: 385.3511\n",
            "Epoch 1024/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.0474 - val_loss: 385.5551\n",
            "Epoch 1025/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.6573 - val_loss: 387.7736\n",
            "Epoch 1026/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.4234 - val_loss: 384.3869\n",
            "Epoch 1027/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.4139 - val_loss: 385.5110\n",
            "Epoch 1028/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.7436 - val_loss: 388.6508\n",
            "Epoch 1029/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 361.9281 - val_loss: 384.8270\n",
            "Epoch 1030/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.9291 - val_loss: 390.5172\n",
            "Epoch 1031/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.4549 - val_loss: 384.5246\n",
            "Epoch 1032/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.5903 - val_loss: 386.2534\n",
            "Epoch 1033/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.4981 - val_loss: 385.0348\n",
            "Epoch 1034/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.9042 - val_loss: 386.0370\n",
            "Epoch 1035/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.0975 - val_loss: 384.9741\n",
            "Epoch 1036/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.6053 - val_loss: 386.7041\n",
            "Epoch 1037/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.1354 - val_loss: 384.9248\n",
            "Epoch 1038/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.2943 - val_loss: 384.1281\n",
            "Epoch 1039/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.4341 - val_loss: 386.0242\n",
            "Epoch 1040/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.9352 - val_loss: 384.1359\n",
            "Epoch 1041/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.3035 - val_loss: 384.6071\n",
            "Epoch 1042/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.1178 - val_loss: 384.6237\n",
            "Epoch 1043/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.9656 - val_loss: 384.2589\n",
            "Epoch 1044/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.8514 - val_loss: 385.8125\n",
            "Epoch 1045/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.2311 - val_loss: 383.3885\n",
            "Epoch 1046/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.7942 - val_loss: 385.1850\n",
            "Epoch 1047/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.1305 - val_loss: 384.4836\n",
            "Epoch 1048/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.5788 - val_loss: 386.2908\n",
            "Epoch 1049/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.4345 - val_loss: 385.5097\n",
            "Epoch 1050/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.4503 - val_loss: 385.9886\n",
            "Epoch 1051/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.1274 - val_loss: 384.6530\n",
            "Epoch 1052/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.8062 - val_loss: 384.5609\n",
            "Epoch 1053/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.5933 - val_loss: 390.0925\n",
            "Epoch 1054/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 360.0895 - val_loss: 386.7526\n",
            "Epoch 1055/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.7035 - val_loss: 387.4718\n",
            "Epoch 1056/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.5406 - val_loss: 385.1658\n",
            "Epoch 1057/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.0074 - val_loss: 384.1154\n",
            "Epoch 1058/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.7736 - val_loss: 385.9677\n",
            "Epoch 1059/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.6523 - val_loss: 385.6659\n",
            "Epoch 1060/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 359.8083 - val_loss: 384.9388\n",
            "Epoch 1061/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.6935 - val_loss: 383.0788\n",
            "Epoch 1062/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.2765 - val_loss: 383.9139\n",
            "Epoch 1063/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.5253 - val_loss: 383.6382\n",
            "Epoch 1064/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.4250 - val_loss: 385.2568\n",
            "Epoch 1065/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.4985 - val_loss: 383.4916\n",
            "Epoch 1066/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.4755 - val_loss: 385.4331\n",
            "Epoch 1067/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.2619 - val_loss: 384.6271\n",
            "Epoch 1068/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.8382 - val_loss: 383.4080\n",
            "Epoch 1069/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.5847 - val_loss: 383.8279\n",
            "Epoch 1070/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.7439 - val_loss: 384.2801\n",
            "Epoch 1071/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.5475 - val_loss: 384.8553\n",
            "Epoch 1072/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.0172 - val_loss: 384.0436\n",
            "Epoch 1073/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.4139 - val_loss: 382.4684\n",
            "Epoch 1074/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.6069 - val_loss: 383.3999\n",
            "Epoch 1075/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.3970 - val_loss: 384.4429\n",
            "Epoch 1076/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.9406 - val_loss: 383.8017\n",
            "Epoch 1077/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.8694 - val_loss: 383.4948\n",
            "Epoch 1078/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 356.8908 - val_loss: 383.0194\n",
            "Epoch 1079/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.7405 - val_loss: 384.6311\n",
            "Epoch 1080/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.5859 - val_loss: 385.4924\n",
            "Epoch 1081/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.8516 - val_loss: 382.9506\n",
            "Epoch 1082/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.8134 - val_loss: 382.8795\n",
            "Epoch 1083/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.4131 - val_loss: 382.6834\n",
            "Epoch 1084/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.3412 - val_loss: 383.8206\n",
            "Epoch 1085/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 356.9500 - val_loss: 384.0222\n",
            "Epoch 1086/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.8286 - val_loss: 383.0257\n",
            "Epoch 1087/2500\n",
            "139/139 [==============================] - 0s 2ms/step - loss: 358.1067 - val_loss: 384.1265\n",
            "Epoch 1088/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 356.9391 - val_loss: 385.6490\n",
            "Epoch 1089/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 356.8267 - val_loss: 385.6320\n",
            "Epoch 1090/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 358.5480 - val_loss: 388.5057\n",
            "Epoch 1091/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.8948 - val_loss: 382.9590\n",
            "Epoch 1092/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.1498 - val_loss: 382.7984\n",
            "Epoch 1093/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.0962 - val_loss: 383.1530\n",
            "Epoch 1094/2500\n",
            "139/139 [==============================] - 0s 3ms/step - loss: 357.0038 - val_loss: 384.1689\n",
            "Epoch 1094: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1c6ce69210>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizar a convergência da rede neural\n",
        "# perdas = pd.DataFrame(modelo.history.history)\n",
        "# perdas.plot()\n",
        "\n",
        "perdas_loss = pd.DataFrame(modelo.history.history['loss'])\n",
        "perdas_val_loss = pd.DataFrame(modelo.history.history['val_loss'])\n",
        "\n",
        "perdas_loss_plot = plt.plot(perdas_loss.index, perdas_loss[0], label='Treino')\n",
        "perdas_val_loss_plot = plt.plot(perdas_val_loss.index, perdas_val_loss[0], label='Teste')\n",
        "\n",
        "plt.title('Perda / Erro Quadrado Médio - mse')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "d-D3qJnbRtfc",
        "outputId": "ea56537f-3a45-47c4-a621-5c69ae7bd7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# valores que a rede está prevendo\n",
        "previsoes = modelo.predict(X_teste)\n",
        "previsoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAsNQBTXR4BL",
        "outputId": "c859fc35-ea42-4f56-a60d-6aabf36b5121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[38.817844],\n",
              "       [52.617275],\n",
              "       [20.334005],\n",
              "       ...,\n",
              "       [59.906822],\n",
              "       [49.801525],\n",
              "       [55.38109 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a previsão da rede versus os valores corretos que vc já sabe, mas não deixou a rede saber\n",
        "df = pd.DataFrame(previsoes, y_teste)\n",
        "df_resetada = df.reset_index()\n",
        "df_resetada_renomeada = df_resetada.rename(columns={\"index\": \"Previsão da rede\", 0: \"Valores corretos\"})\n",
        "df_resetada_renomeada"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Xz-Ldk3kSJB7",
        "outputId": "d6da6f1d-1b65-415f-82fc-76bba28ce232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Previsão da rede  Valores corretos\n",
              "0                45.38         38.817844\n",
              "1                50.17         52.617275\n",
              "2                12.20         20.334005\n",
              "3                46.03         65.042511\n",
              "4                47.21         61.835258\n",
              "...                ...               ...\n",
              "1468             45.33         38.289410\n",
              "1469             14.16         26.554461\n",
              "1470             27.05         59.906822\n",
              "1471             62.68         49.801525\n",
              "1472             64.53         55.381088\n",
              "\n",
              "[1473 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68662285-19a3-4c8a-acc3-3be50347d0ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Previsão da rede</th>\n",
              "      <th>Valores corretos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45.38</td>\n",
              "      <td>38.817844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50.17</td>\n",
              "      <td>52.617275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12.20</td>\n",
              "      <td>20.334005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>46.03</td>\n",
              "      <td>65.042511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>47.21</td>\n",
              "      <td>61.835258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1468</th>\n",
              "      <td>45.33</td>\n",
              "      <td>38.289410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>14.16</td>\n",
              "      <td>26.554461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1470</th>\n",
              "      <td>27.05</td>\n",
              "      <td>59.906822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1471</th>\n",
              "      <td>62.68</td>\n",
              "      <td>49.801525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1472</th>\n",
              "      <td>64.53</td>\n",
              "      <td>55.381088</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1473 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68662285-19a3-4c8a-acc3-3be50347d0ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68662285-19a3-4c8a-acc3-3be50347d0ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68662285-19a3-4c8a-acc3-3be50347d0ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# média dos dados que a rede está prevendo, comparando os dois: loss e val_loss\n",
        "mean_squared_error(y_teste, previsoes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1m-pHkSR7Wr",
        "outputId": "eff01ca5-c039-47d2-b616-1cb77a5f43a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384.1688587524638"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# é o erro ao quadrado, este número é a média de erro na coluna y\n",
        "np.sqrt(mean_squared_error(y_teste, previsoes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-rKnzdUSAxj",
        "outputId": "2554db05-c244-4939-eca4-a477ad308a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.600225987280446"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# eficiência da rede neural, onde o número 0.0145 seria apenas 1% de eficiência\n",
        "explained_variance_score(y_teste, previsoes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQrtXYo7SDqb",
        "outputId": "a2441d90-5927-4f81-8ba9-052e1064ba42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3675539056634952"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Marina Micas Jardim\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "###### Trabalho de Conclusão de Curso apresentado ao Curso de Especialização em Inteligência Artificial e Aprendizado de Máquina, como requisito parcial à obtenção do título de Especialista.\n"
      ],
      "metadata": {
        "id": "vefkSWc3Tzov"
      }
    }
  ]
}